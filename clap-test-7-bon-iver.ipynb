{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T12:01:00.350842Z",
     "start_time": "2025-06-22T12:00:54.864896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "!pip install datasets transformers librosa soundfile numpy\"<\"2 torch torchaudio fast-tsp kmedoids\n"
   ],
   "id": "b7880da606420f96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./venv/lib/python3.12/site-packages (3.6.0)\r\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.12/site-packages (4.52.4)\r\n",
      "Requirement already satisfied: librosa in ./venv/lib/python3.12/site-packages (0.11.0)\r\n",
      "Requirement already satisfied: soundfile in ./venv/lib/python3.12/site-packages (0.13.1)\r\n",
      "Requirement already satisfied: numpy<2 in ./venv/lib/python3.12/site-packages (1.26.4)\r\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.12/site-packages (2.2.1)\r\n",
      "Requirement already satisfied: torchaudio in ./venv/lib/python3.12/site-packages (2.2.1)\r\n",
      "Requirement already satisfied: fast-tsp in ./venv/lib/python3.12/site-packages (0.1.4)\r\n",
      "Collecting kmedoids\r\n",
      "  Obtaining dependency information for kmedoids from https://files.pythonhosted.org/packages/6e/b4/457e552aa362cc746fbf0c461ab1a9bd7794db3321f82586601769f27112/kmedoids-0.5.3.1-cp312-cp312-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata\r\n",
      "  Downloading kmedoids-0.5.3.1-cp312-cp312-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (9.6 kB)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from datasets) (3.18.0)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./venv/lib/python3.12/site-packages (from datasets) (20.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./venv/lib/python3.12/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (from datasets) (2.3.0)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in ./venv/lib/python3.12/site-packages (from datasets) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./venv/lib/python3.12/site-packages (from datasets) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in ./venv/lib/python3.12/site-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./venv/lib/python3.12/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in ./venv/lib/python3.12/site-packages (from datasets) (2025.3.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./venv/lib/python3.12/site-packages (from datasets) (0.33.0)\r\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from datasets) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from datasets) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./venv/lib/python3.12/site-packages (from transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.12/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./venv/lib/python3.12/site-packages (from librosa) (3.0.1)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in ./venv/lib/python3.12/site-packages (from librosa) (0.61.2)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.15.3)\r\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.7.0)\r\n",
      "Requirement already satisfied: joblib>=1.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.5.1)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./venv/lib/python3.12/site-packages (from librosa) (5.2.1)\r\n",
      "Requirement already satisfied: pooch>=1.1 in ./venv/lib/python3.12/site-packages (from librosa) (1.8.2)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./venv/lib/python3.12/site-packages (from librosa) (0.5.0.post1)\r\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in ./venv/lib/python3.12/site-packages (from librosa) (4.14.0)\r\n",
      "Requirement already satisfied: lazy_loader>=0.1 in ./venv/lib/python3.12/site-packages (from librosa) (0.4)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.1.1)\r\n",
      "Requirement already satisfied: cffi>=1.0 in ./venv/lib/python3.12/site-packages (from soundfile) (1.17.1)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.12/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.12/site-packages (from cffi>=1.0->soundfile) (2.22)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./venv/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\r\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./venv/lib/python3.12/site-packages (from numba>=0.51.0->librosa) (0.44.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./venv/lib/python3.12/site-packages (from pooch>=1.1->librosa) (4.3.8)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
      "Downloading kmedoids-0.5.3.1-cp312-cp312-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (915 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m915.7/915.7 kB\u001B[0m \u001B[31m9.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hInstalling collected packages: kmedoids\r\n",
      "Successfully installed kmedoids-0.5.3.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "3cb23ac2-7d44-42dc-8acf-0df92184c026",
   "metadata": {},
   "source": "# Setup"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:49:06.968638Z",
     "start_time": "2025-06-22T19:48:50.399673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformers import ClapModel, ClapFeatureExtractor, AutoTokenizer\n",
    "\n",
    "device='mps'\n",
    "model = ClapModel.from_pretrained(\"laion/clap-htsat-unfused\", use_safetensors=True).to(device)\n",
    "feature_extractor: ClapFeatureExtractor = ClapFeatureExtractor.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"laion/clap-htsat-unfused\")\n"
   ],
   "id": "5a78d7169b407d7d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run",
   "id": "6d42f4e095b6da6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:49:41.174613Z",
     "start_time": "2025-06-22T19:49:38.973325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "filename = '/Users/damian/Downloads/Bon Iver - Michicant (Deluxe) - Official Video.mp3'\n",
    "waveform, sampling_rate = torchaudio.load(filename)\n",
    "chunk_beats = 2\n",
    "bpm = 161/2\n",
    "window_width = 0\n",
    "\n",
    "if sampling_rate != feature_extractor.sampling_rate:\n",
    "    resampler = T.Resample(sampling_rate,  feature_extractor.sampling_rate, dtype=waveform.dtype)\n",
    "    waveform, sampling_rate = resampler(waveform), feature_extractor.sampling_rate\n",
    "\n",
    "print(sampling_rate, waveform.shape)\n",
    "#inputs = feature_extractor(waveform, sampling_rate=sample_rate, return_tensors=\"pt\")\n",
    "#audio_features = model.get_audio_features(**inputs)"
   ],
   "id": "d5d30b5e7ea5cb98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 torch.Size([2, 11764158])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:49:41.244201Z",
     "start_time": "2025-06-22T19:49:41.180249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Generator\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def wrap(idx, total):\n",
    "    if idx < 0:\n",
    "        return total + idx\n",
    "    elif idx >= total:\n",
    "        return idx - total\n",
    "    else:\n",
    "        return idx\n",
    "    \n",
    "def get_audio_chunks(waveform, chunk_size_seconds: float=0.25, \n",
    "                     window_width: float=0, include_window: bool=True\n",
    "             ) -> Generator[torch.Tensor, None, None]:\n",
    "    if len(waveform.shape) != 1:\n",
    "        raise ValueError(\"waveform should have shape [num_samples]\")\n",
    "    chunk_size = int(8 * ((sampling_rate * chunk_size_seconds) // 8))\n",
    "    window_width_samples = int(chunk_size * window_width)\n",
    "    for offset in range(window_width_samples, waveform.shape[0]-window_width_samples, chunk_size):\n",
    "        if include_window:\n",
    "            start = wrap(offset-window_width_samples, waveform.shape[0])\n",
    "            end = wrap(offset+chunk_size+window_width_samples, waveform.shape[0])\n",
    "        else:\n",
    "            start = offset\n",
    "            end = offset + chunk_size\n",
    "        yield waveform[start:end]\n",
    "    \n",
    "\n",
    "def get_audio_features(waveform: torch.Tensor, sampling_rate):\n",
    "    inputs = feature_extractor(waveform, sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "    #print(inputs.keys())\n",
    "    audio_features = model.get_audio_features(input_features=inputs.input_features.to(device))\n",
    "    return audio_features / torch.norm(audio_features, p=2, dim=1, keepdim=True)\n",
    "\n",
    "def get_text_features(text: str):\n",
    "    inputs = tokenizer(text, padding=True, return_tensors='pt')\n",
    "    text_features =  model.get_text_features(input_ids = inputs.input_ids.to(device))\n",
    "    return text_features / torch.norm(text_features, p=2, dim=1, keepdim=True)\n"
   ],
   "id": "5b4b82f01c2ca14b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:50:25.548779Z",
     "start_time": "2025-06-22T19:49:41.473942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "chunk_size_seconds = chunk_beats*60/bpm\n",
    "left_chunks_window = list(get_audio_chunks(waveform[0], chunk_size_seconds=chunk_size_seconds, window_width=window_width))[:-1]\n",
    "right_chunks_window = list(get_audio_chunks(waveform[1], chunk_size_seconds=chunk_size_seconds, window_width=window_width))[:-1]\n",
    "mono_chunks = [(left_chunks_window[i] + right_chunks_window[i]) / 2 for i in range(len(left_chunks_window))]\n",
    "\n",
    "left_chunks_no_window = list(get_audio_chunks(waveform[0], chunk_size_seconds=chunk_size_seconds, window_width=window_width, include_window=False))[:-1]\n",
    "right_chunks_no_window = list(get_audio_chunks(waveform[1], chunk_size_seconds=chunk_size_seconds, window_width=window_width, include_window=False))[:-1]\n",
    "stereo_chunks_no_window = [torch.stack([left_chunks_no_window[index], right_chunks_no_window[index]])\n",
    "    for index in range(len(left_chunks_no_window))]\n",
    "features_pickle_filename = filename + f'.clap-norm-bpm{bpm}-cb{chunk_beats}-ww{window_width}.pkl'\n",
    "if os.path.exists(features_pickle_filename):\n",
    "    with open(features_pickle_filename, 'rb') as f:\n",
    "        all_features = pickle.load(f)\n",
    "else:\n",
    "    all_features = torch.concat([get_audio_features(chunk, sampling_rate=sampling_rate) \n",
    "                             for chunk in tqdm(mono_chunks)])\n",
    "    with open(features_pickle_filename, 'wb') as f:\n",
    "        pickle.dump(all_features, f)\n",
    "\n"
   ],
   "id": "c691f5b529b7e6c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23703583a1df4f0ca616e5e25e9c476b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damian/2.current/clapSlice/venv/lib/python3.12/site-packages/torch/nn/functional.py:4046: UserWarning: The operator 'aten::upsample_bicubic2d.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:50:27.116232Z",
     "start_time": "2025-06-22T19:50:25.554813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from medoids_tsp import sort_tsp\n",
    "sort_order = sort_tsp(all_features)"
   ],
   "id": "b6a9e3a09263202d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing distance matrix\n",
      "computing route\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:50:27.352167Z",
     "start_time": "2025-06-22T19:50:27.117916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chunks_sorted = [torch.stack([left_chunks_no_window[index], right_chunks_no_window[index]])\n",
    "    for index in sort_order]\n",
    "print(chunks_sorted[0].shape)\n",
    "sorted_audio = torch.cat(chunks_sorted, dim=1)\n",
    "print(sorted_audio.shape)"
   ],
   "id": "87f9d40beaf70379",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 71552])\n",
      "torch.Size([2, 11734528])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:50:27.432303Z",
     "start_time": "2025-06-22T19:50:27.357557Z"
    }
   },
   "cell_type": "code",
   "source": "sort_order",
   "id": "7a3153fb417164b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 25, 100, 115, 117, 104, 109, 103, 102, 116, 110, 123,  51, 126,  74,\n",
       "         75,  58,  41,  28,  21,  22,  42,  36,  29,  35,  77,  78,  76,  71,\n",
       "         57,  70,  65,  52,  64, 151, 133, 134, 152, 142, 149, 144, 148, 146,\n",
       "        155, 156, 153, 145, 150, 147, 141, 139, 154, 136, 138, 132, 137, 143,\n",
       "        140, 135, 129, 128, 130, 158, 157,  97,  79,  86,  82,  88,  85,  83,\n",
       "         91,  90,  89,  87,  92, 122, 127,  95,  96,  94,  84,  93,  81,  80,\n",
       "        159, 160, 161, 162, 163,   0,   1,   3,   4,   8,  10,  11,   9,   7,\n",
       "          6,   5,  12,   2,  14,  15,  16,  46,  72,  50, 131,  43, 105, 118,\n",
       "         63,  30,  34,  23,  13,  45,  20,  40,  27,  59, 111,  26,  44, 101,\n",
       "         49,  47,  62, 107,  55,  66,  53,  68, 125,  73, 124, 121, 108,  56,\n",
       "         69,  39,  98, 113,  61,  32,  38,  24,  99,  17,  18, 106, 112,  60,\n",
       "        119,  37,  31,  67,  33, 114, 120,  19,  48,  54])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:18:53.291394Z",
     "start_time": "2025-06-22T19:18:51.641317Z"
    }
   },
   "cell_type": "code",
   "source": "torchaudio.save(filename + f'-sorted-norm-bpm{bpm}-cb{chunk_beats}-ww{window_width}.wav', sorted_audio, sample_rate=sampling_rate)",
   "id": "7350c7926c1c6c7b",
   "outputs": [],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:52:05.307431Z",
     "start_time": "2025-06-22T19:51:58.941273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Literal\n",
    "import math\n",
    "\n",
    "def smear(chunks, smear_width):\n",
    "    envelope = 0.5*(1-torch.cos(torch.linspace(0, 2*math.pi, 2*smear_width+1)))\n",
    "    #for i in range(smear_width+1, 2*smear_width+1):\n",
    "    #    envelope[i] = 0\n",
    "    print(envelope)\n",
    "    for i in range(len(chunks)-smear_width*2-1):\n",
    "        smear_sources = [\n",
    "            chunks[i+chunk_index] * envelope[chunk_index]\n",
    "            #(i+chunk_index, envelope[chunk_index])\n",
    "            for chunk_index in range(0, min(len(chunks), smear_width*2+1))\n",
    "        ]\n",
    "        #print(smear_sources)\n",
    "        #print(set([ss.shape for ss in smear_sources]))\n",
    "        #print(torch.sum(torch.stack(smear_sources), dim=0))\n",
    "        smeared_chunk = torch.sum(torch.stack(smear_sources), dim=0) / len(smear_sources)\n",
    "        #print(smeared_chunk.shape)\n",
    "        #break\n",
    "        yield smeared_chunk\n",
    "        \n",
    "def smear_2(original_order_chunks_no_window, sort_order, smear_width, spread=4, \n",
    "            smear_mode=Literal['in', 'in-out'],\n",
    "            dynamic_smear_width_embeds: tuple[torch.Tensor, list[int]]=None):\n",
    "    \n",
    "    def get_envelope(smear_width):\n",
    "        envelope = 0.5*(1-torch.cos(torch.linspace(0, 2*math.pi, 2*smear_width+1)))\n",
    "        if smear_mode == 'in':\n",
    "            for i in range(smear_width+1, 2*smear_width+1):\n",
    "                envelope[i] = 0\n",
    "        return envelope\n",
    "    envelope = get_envelope(smear_width)\n",
    "    print(envelope)\n",
    "    num_chunks = len(original_order_chunks_no_window)\n",
    "    smeared_chunks = [torch.zeros_like(original_order_chunks_no_window[0]) \n",
    "                     for _ in range(num_chunks)]\n",
    "    for position_idx in tqdm(range(num_chunks), total=num_chunks):\n",
    "        source_chunk_idx = sort_order[position_idx]\n",
    "        \n",
    "        if dynamic_smear_width_embeds is not None:\n",
    "            source_chunk_embed = all_features[source_chunk_idx]\n",
    "            logits = source_chunk_embed @ dynamic_smear_width_embeds[0].T\n",
    "            #print(logits)\n",
    "            #print(logits.softmax(dim=0))\n",
    "            smear_width = torch.sum((logits / logits.sum()) \n",
    "                                              * torch.tensor(dynamic_smear_width_embeds[1]).to(device)).item()\n",
    "            print(smear_width)\n",
    "            smear_width = max(round(smear_width), 1)\n",
    "            envelope = get_envelope(smear_width)\n",
    "                    \n",
    "        for smear_slot in range(-smear_width, smear_width+1):\n",
    "            for spread_slot in range(-spread, spread+1):\n",
    "                smeared_chunks[\n",
    "                    wrap(position_idx+smear_slot+spread_slot, num_chunks)\n",
    "                ] += (\n",
    "                        original_order_chunks_no_window[\n",
    "                            wrap(source_chunk_idx+spread_slot, num_chunks)]\n",
    "                        * envelope[smear_slot+smear_width] \n",
    "                        * (1/((spread+1)*envelope.sum()))\n",
    "                )\n",
    "\n",
    "    for smeared_chunk in smeared_chunks:\n",
    "        yield smeared_chunk\n",
    "        \n",
    "    #for i \n",
    "smear_width = 1\n",
    "spread = 4\n",
    "smear_mode = 'in-out'\n",
    "\n",
    "dynamic_smear_width_defs = [('dreamy, mysterious, sparse', 6), ('intense, emotional, screaming, wailing', 1)]\n",
    "print(tokenizer('stuff', padding=True, return_tensors='pt').input_ids)\n",
    "\n",
    "dynamic_smear_width_embeds = (\n",
    "    torch.concat([get_text_features(s) for s, _ in dynamic_smear_width_defs]),\n",
    "    [w for _, w in dynamic_smear_width_defs]\n",
    ")\n",
    "\n",
    "smeared_chunks = list(smear_2(stereo_chunks_no_window, sort_order=sort_order, smear_width=smear_width, spread=spread, smear_mode=smear_mode, \n",
    "                              #dynamic_smear_width_embeds=dynamic_smear_width_embeds\n",
    "                              ))\n",
    "#print(Counter([len(c) for c in smeared_chunks]))\n",
    "smeared = torch.cat(smeared_chunks, dim=1)\n",
    "print(smeared.shape)\n",
    "torchaudio.save(filename + f'-sorted-norm-bpm{bpm}-cb{chunk_beats}-ww{window_width}-smeared-sm_{smear_mode}-sw{smear_width}-spread_actual{spread}.wav', smeared, sample_rate=sampling_rate)\n"
   ],
   "id": "2e343d37b2782fd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0, 40110,     2]])\n",
      "tensor([0., 1., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "267160452a814710822fb07bb72bb6e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 11734528])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T20:19:43.746657Z",
     "start_time": "2025-06-22T20:19:40.176345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Literal\n",
    "import math\n",
    "\n",
    "def smear(chunks, smear_width):\n",
    "    envelope = 0.5*(1-torch.cos(torch.linspace(0, 2*math.pi, 2*smear_width+1)))\n",
    "    #for i in range(smear_width+1, 2*smear_width+1):\n",
    "    #    envelope[i] = 0\n",
    "    print(envelope)\n",
    "    for i in range(len(chunks)-smear_width*2-1):\n",
    "        smear_sources = [\n",
    "            chunks[i+chunk_index] * envelope[chunk_index]\n",
    "            #(i+chunk_index, envelope[chunk_index])\n",
    "            for chunk_index in range(0, min(len(chunks), smear_width*2+1))\n",
    "        ]\n",
    "        #print(smear_sources)\n",
    "        #print(set([ss.shape for ss in smear_sources]))\n",
    "        #print(torch.sum(torch.stack(smear_sources), dim=0))\n",
    "        smeared_chunk = torch.sum(torch.stack(smear_sources), dim=0) / len(smear_sources)\n",
    "        #print(smeared_chunk.shape)\n",
    "        #break\n",
    "        yield smeared_chunk\n",
    "        \n",
    "def smear_2(original_order_chunks_no_window, sort_order, smear_width, spread=4, \n",
    "            smear_mode=Literal['in', 'in-out'],\n",
    "            dynamic_smear_width_embeds: tuple[torch.Tensor, list[int], list[int]]=None):\n",
    "    \n",
    "    def get_envelope(smear_width):\n",
    "        envelope = 0.5*(1-torch.cos(torch.linspace(0, 2*math.pi, 2*smear_width+1)))\n",
    "        if smear_mode == 'in':\n",
    "            for i in range(smear_width+1, 2*smear_width+1):\n",
    "                envelope[i] = 0\n",
    "        return envelope\n",
    "    envelope = get_envelope(smear_width)\n",
    "    print(envelope)\n",
    "    num_chunks = len(original_order_chunks_no_window)\n",
    "    smeared_chunks = [torch.zeros_like(original_order_chunks_no_window[0]) \n",
    "                     for _ in range(num_chunks)]\n",
    "    for position_idx in tqdm(range(num_chunks), total=num_chunks):\n",
    "        source_chunk_idx = sort_order[position_idx]\n",
    "        \n",
    "        if dynamic_smear_width_embeds is not None:\n",
    "            source_chunk_embed = all_features[source_chunk_idx]\n",
    "            logits = source_chunk_embed @ dynamic_smear_width_embeds[0].T\n",
    "            #print(logits)\n",
    "            #print(logits.softmax(dim=0))\n",
    "            logits_norm = logits / logits.sum()\n",
    "            smooth_dynamic_smear = True\n",
    "            if smooth_dynamic_smear:\n",
    "                smear_width = torch.sum(\n",
    "                    logits_norm \n",
    "                    * torch.tensor(dynamic_smear_width_embeds[1]).to(device)\n",
    "                ).item()\n",
    "                spread = torch.sum(\n",
    "                    logits_norm \n",
    "                    * torch.tensor(dynamic_smear_width_embeds[2]).to(device)\n",
    "                ).item()\n",
    "                print(smear_width, spread)\n",
    "                smear_width = max(round(smear_width), 1)\n",
    "                spread = max(round(spread), 1)\n",
    "            else:\n",
    "                smear_width = dynamic_smear_width_embeds[1][int(logits_norm.argmax().item())]\n",
    "                spread = dynamic_smear_width_embeds[2][int(logits_norm.argmax().item())]\n",
    "                print(smear_width, spread)\n",
    "            envelope = get_envelope(smear_width)\n",
    "        #volume_scaling = 1/envelope.sum()\n",
    "        \n",
    "        noclip_ramp = 200\n",
    "        chunk_size_samples = original_order_chunks_no_window[0].shape[1]\n",
    "        spread_envelope_in = torch.cat([torch.linspace(0, 1, noclip_ramp),\n",
    "                                            torch.ones(chunk_size_samples-noclip_ramp)])\n",
    "        spread_envelope_out = torch.cat([torch.ones(chunk_size_samples-noclip_ramp), \n",
    "                                                 torch.linspace(1, 0, noclip_ramp)])\n",
    "        spread_envelope_flat = torch.ones(chunk_size_samples)\n",
    "        spread_envelope = [spread_envelope_in] + [spread_envelope_flat] * (2*spread-1) + [spread_envelope_out]\n",
    "        for smear_slot in range(-smear_width, smear_width+1):\n",
    "            for spread_slot in range(-spread, spread+1):\n",
    "                smeared_chunks[\n",
    "                    wrap(position_idx+smear_slot+spread_slot, num_chunks)\n",
    "                ] += (\n",
    "                        original_order_chunks_no_window[\n",
    "                            wrap(source_chunk_idx+spread_slot, num_chunks)]\n",
    "                        * envelope[smear_slot+smear_width] \n",
    "                        * (1/((spread+1)*envelope.sum()))\n",
    "                        * spread_envelope[spread_slot+spread]\n",
    "                )\n",
    "\n",
    "    for smeared_chunk in smeared_chunks:\n",
    "        yield smeared_chunk\n",
    "        \n",
    "    #for i \n",
    "spread = 4\n",
    "smear_width = 1\n",
    "smear_mode = 'in-out'\n",
    "\n",
    "dynamic_smear_width_defs = [('a tenor voice sings softly, mysterious, sparse', 4, 1), \n",
    "                            ('gentle acoustic jazz instruments make a lovely soundscape', 1, 4), \n",
    "                            #('intense, emotional, screaming, wailing', 1, 6)\n",
    "                            ]\n",
    "print(tokenizer('stuff', padding=True, return_tensors='pt').input_ids)\n",
    "\n",
    "dynamic_smear_width_embeds = (\n",
    "    torch.concat([get_text_features(t) for t, _, _ in dynamic_smear_width_defs]),\n",
    "    [w for _, w, _ in dynamic_smear_width_defs],\n",
    "    [s for _, _, s in dynamic_smear_width_defs]\n",
    ")\n",
    "\n",
    "smeared_chunks = list(smear_2(stereo_chunks_no_window, sort_order=sort_order, smear_width=smear_width, spread=spread, smear_mode=smear_mode, \n",
    "                              dynamic_smear_width_embeds=dynamic_smear_width_embeds\n",
    "                              ))\n",
    "#print(Counter([len(c) for c in smeared_chunks]))\n",
    "smeared = torch.cat(smeared_chunks, dim=1)\n",
    "print(smeared.shape)\n",
    "torchaudio.save(filename + f'-sorted-norm-bpm{bpm}-cb{chunk_beats}-ww{window_width}-smeared-sm_{smear_mode}-sw{smear_width}-spread_actual{spread}-dyn3a-env.wav', smeared, sample_rate=sampling_rate)\n"
   ],
   "id": "c11ef4e4ff8baf4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0, 40110,     2]])\n",
      "tensor([0., 1., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd80c94d42424cf8a6ac2bd027c13433"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.343362808227539 2.656637191772461\n",
      "2.642634391784668 2.357365369796753\n",
      "1.8989572525024414 3.1010427474975586\n",
      "1.7994635105133057 3.2005367279052734\n",
      "1.7540531158447266 3.2459468841552734\n",
      "1.5838580131530762 3.416142463684082\n",
      "1.723629117012024 3.2763710021972656\n",
      "1.6055140495300293 3.3944857120513916\n",
      "1.7240736484527588 3.275926113128662\n",
      "1.7892026901245117 3.21079683303833\n",
      "1.6229168176651 3.3770830631256104\n",
      "1.6846914291381836 3.3153088092803955\n",
      "2.03239107131958 2.96760892868042\n",
      "2.048370361328125 2.951629638671875\n",
      "2.1246886253356934 2.8753111362457275\n",
      "1.8424794673919678 3.1575207710266113\n",
      "1.9157613515853882 3.0842387676239014\n",
      "2.0313029289245605 2.9686973094940186\n",
      "2.186267614364624 2.813732385635376\n",
      "2.3249452114105225 2.6750547885894775\n",
      "2.3317489624023438 2.6682510375976562\n",
      "2.2716400623321533 2.7283599376678467\n",
      "2.339428663253784 2.6605710983276367\n",
      "2.4336161613464355 2.5663836002349854\n",
      "2.4699482917785645 2.5300517082214355\n",
      "2.5218658447265625 2.4781341552734375\n",
      "2.3601691722869873 2.6398308277130127\n",
      "1.366907000541687 3.6330926418304443\n",
      "0.8206166625022888 4.179383277893066\n",
      "1.6305370330810547 3.3694632053375244\n",
      "1.0833606719970703 3.9166393280029297\n",
      "1.6148970127105713 3.385103225708008\n",
      "1.6525182723999023 3.3474819660186768\n",
      "1.1660749912261963 3.8339247703552246\n",
      "1.9288203716278076 3.0711796283721924\n",
      "1.4317936897277832 3.568206310272217\n",
      "1.499953031539917 3.500046968460083\n",
      "1.8723499774932861 3.127650260925293\n",
      "1.6641340255737305 3.3358659744262695\n",
      "0.9419643878936768 4.058035373687744\n",
      "1.9196796417236328 3.0803205966949463\n",
      "1.7903387546539307 3.2096614837646484\n",
      "1.4899630546569824 3.5100367069244385\n",
      "0.8409395813941956 4.159060478210449\n",
      "-1.2605209350585938 6.2605204582214355\n",
      "1.0116220712661743 3.9883782863616943\n",
      "0.9791924357414246 4.020807266235352\n",
      "0.9709433317184448 4.029057025909424\n",
      "1.144032597541809 3.8559675216674805\n",
      "1.4214768409729004 3.5785229206085205\n",
      "1.4318463802337646 3.5681538581848145\n",
      "1.0232484340667725 3.9767515659332275\n",
      "0.9745728969573975 4.025426864624023\n",
      "1.6918691396713257 3.3081307411193848\n",
      "1.32764732837677 3.6723525524139404\n",
      "1.2833844423294067 3.7166154384613037\n",
      "1.718637466430664 3.281362771987915\n",
      "1.4919339418411255 3.508066177368164\n",
      "1.7076995372772217 3.2923007011413574\n",
      "1.678613305091858 3.3213865756988525\n",
      "1.7899093627929688 3.2100906372070312\n",
      "1.27925705909729 3.720742702484131\n",
      "1.7029838562011719 3.2970163822174072\n",
      "0.8040170669555664 4.195982933044434\n",
      "1.9585540294647217 3.0414459705352783\n",
      "2.013024091720581 2.986976146697998\n",
      "2.021872043609619 2.978127956390381\n",
      "2.0126843452453613 2.9873158931732178\n",
      "1.9373605251312256 3.0626392364501953\n",
      "1.9000232219696045 3.0999767780303955\n",
      "1.7552950382232666 3.2447049617767334\n",
      "1.8878586292266846 3.1121413707733154\n",
      "1.7996541261672974 3.200345993041992\n",
      "1.8113282918930054 3.188671827316284\n",
      "1.817102313041687 3.1828980445861816\n",
      "1.8888460397720337 3.111154317855835\n",
      "1.9275184869766235 3.072481870651245\n",
      "1.6598552465438843 3.3401448726654053\n",
      "1.3933119773864746 3.6066880226135254\n",
      "2.107304573059082 2.892695426940918\n",
      "2.2124853134155273 2.7875144481658936\n",
      "2.060976028442383 2.939023733139038\n",
      "2.9285316467285156 2.0714683532714844\n",
      "2.424407958984375 2.575592041015625\n",
      "3.325090169906616 1.6749097108840942\n",
      "1.3872679471969604 3.61273193359375\n",
      "-1.8860926628112793 6.886092662811279\n",
      "3.4644172191619873 1.5355827808380127\n",
      "2.5333807468414307 2.4666194915771484\n",
      "2.5021214485168457 2.497878074645996\n",
      "2.672692060470581 2.32730770111084\n",
      "2.7475802898406982 2.2524197101593018\n",
      "2.9132864475250244 2.0867133140563965\n",
      "2.907851219177246 2.092148780822754\n",
      "2.566514253616333 2.433485507965088\n",
      "2.662105083465576 2.337894916534424\n",
      "2.5493452548980713 2.450654983520508\n",
      "2.541743278503418 2.458256959915161\n",
      "2.530975341796875 2.469024658203125\n",
      "2.7293410301208496 2.2706594467163086\n",
      "2.8206565380096436 2.1793432235717773\n",
      "2.961442708969116 2.038557529449463\n",
      "2.6162497997283936 2.3837502002716064\n",
      "-0.3936018943786621 5.39360237121582\n",
      "3.0930254459381104 1.9069749116897583\n",
      "3.101379871368408 1.89862060546875\n",
      "2.699965000152588 2.300034761428833\n",
      "2.16953182220459 2.83046817779541\n",
      "4.080353736877441 0.9196462035179138\n",
      "2.8096280097961426 2.1903719902038574\n",
      "2.454741954803467 2.545258045196533\n",
      "2.2340636253356934 2.7659361362457275\n",
      "2.353724956512451 2.6462748050689697\n",
      "2.4281046390533447 2.571895122528076\n",
      "2.670098066329956 2.329901695251465\n",
      "1.793927550315857 3.2060725688934326\n",
      "2.008021593093872 2.991978406906128\n",
      "2.283743381500244 2.716256856918335\n",
      "2.309317111968994 2.690683364868164\n",
      "2.071409225463867 2.928591012954712\n",
      "2.3446619510650635 2.6553382873535156\n",
      "2.7995340824127197 2.200465679168701\n",
      "2.3995985984802246 2.6004014015197754\n",
      "2.4450438022613525 2.5549561977386475\n",
      "3.069054126739502 1.930945873260498\n",
      "2.3594765663146973 2.640523672103882\n",
      "2.21097731590271 2.78902268409729\n",
      "2.001345157623291 2.998654842376709\n",
      "2.5842740535736084 2.4157257080078125\n",
      "2.55525279045105 2.4447474479675293\n",
      "2.4874517917633057 2.5125482082366943\n",
      "2.5965375900268555 2.4034624099731445\n",
      "2.3921337127685547 2.607866048812866\n",
      "2.6546032428741455 2.3453965187072754\n",
      "2.603456497192383 2.396543502807617\n",
      "2.5348167419433594 2.4651832580566406\n",
      "2.668534278869629 2.331465721130371\n",
      "2.6446645259857178 2.3553357124328613\n",
      "2.13887619972229 2.861123561859131\n",
      "2.421703815460205 2.578296184539795\n",
      "2.139860153198242 2.860139846801758\n",
      "2.4141414165496826 2.5858585834503174\n",
      "2.2258856296539307 2.7741141319274902\n",
      "1.8339619636535645 3.1660382747650146\n",
      "2.271793842315674 2.728206157684326\n",
      "2.2235326766967773 2.7764673233032227\n",
      "2.5994701385498047 2.4005298614501953\n",
      "2.7663822174072266 2.2336180210113525\n",
      "3.045602321624756 1.9543975591659546\n",
      "3.2116191387176514 1.7883806228637695\n",
      "2.7549097537994385 2.2450900077819824\n",
      "2.3897135257720947 2.610286235809326\n",
      "2.326122283935547 2.673877716064453\n",
      "2.56748104095459 2.43251895904541\n",
      "2.864924192428589 2.135075569152832\n",
      "2.983755588531494 2.016244411468506\n",
      "2.670927047729492 2.329072952270508\n",
      "2.5417227745056152 2.4582772254943848\n",
      "1.9053770303726196 3.094623327255249\n",
      "2.3097825050354004 2.6902177333831787\n",
      "2.3543596267700195 2.6456408500671387\n",
      "2.4819576740264893 2.5180420875549316\n",
      "2.5571722984313965 2.4428277015686035\n",
      "2.459524154663086 2.540476083755493\n",
      "torch.Size([2, 11734528])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:40:23.414004Z",
     "start_time": "2025-06-22T19:40:23.301610Z"
    }
   },
   "cell_type": "code",
   "source": "torch.tensor([1, 2, 3]).argmax()",
   "id": "6463b343db5b4966",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 210
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import Literal\n",
    "import math\n",
    "\n",
    "def smear(chunks, smear_width):\n",
    "    envelope = 0.5*(1-torch.cos(torch.linspace(0, 2*math.pi, 2*smear_width+1)))\n",
    "    #for i in range(smear_width+1, 2*smear_width+1):\n",
    "    #    envelope[i] = 0\n",
    "    print(envelope)\n",
    "    for i in range(len(chunks)-smear_width*2-1):\n",
    "        smear_sources = [\n",
    "            chunks[i+chunk_index] * envelope[chunk_index]\n",
    "            #(i+chunk_index, envelope[chunk_index])\n",
    "            for chunk_index in range(0, min(len(chunks), smear_width*2+1))\n",
    "        ]\n",
    "        #print(smear_sources)\n",
    "        #print(set([ss.shape for ss in smear_sources]))\n",
    "        #print(torch.sum(torch.stack(smear_sources), dim=0))\n",
    "        smeared_chunk = torch.sum(torch.stack(smear_sources), dim=0) / len(smear_sources)\n",
    "        #print(smeared_chunk.shape)\n",
    "        #break\n",
    "        yield smeared_chunk\n",
    "        \n",
    "def smear_2(original_order_chunks_no_window, sort_order, smear_width, spread=4, \n",
    "            smear_mode=Literal['in', 'in-out'],\n",
    "            dynamic_smear_width_embeds: tuple[torch.Tensor, list[int], list[int]]=None):\n",
    "    \n",
    "    def get_envelope(smear_width):\n",
    "        envelope = 0.5*(1-torch.cos(torch.linspace(0, 2*math.pi, 2*smear_width+1)))\n",
    "        if smear_mode == 'in':\n",
    "            for i in range(smear_width+1, 2*smear_width+1):\n",
    "                envelope[i] = 0\n",
    "        return envelope\n",
    "    envelope = get_envelope(smear_width)\n",
    "    print(envelope)\n",
    "    num_chunks = len(original_order_chunks_no_window)\n",
    "    smeared_chunks = [torch.zeros_like(original_order_chunks_no_window[0]) \n",
    "                     for _ in range(num_chunks)]\n",
    "    for position_idx in tqdm(range(num_chunks), total=num_chunks):\n",
    "        source_chunk_idx = sort_order[position_idx]\n",
    "        \n",
    "        if dynamic_smear_width_embeds is not None:\n",
    "            source_chunk_embed = all_features[source_chunk_idx]\n",
    "            logits = source_chunk_embed @ dynamic_smear_width_embeds[0].T\n",
    "            #print(logits)\n",
    "            #print(logits.softmax(dim=0))\n",
    "            logits_norm = logits / logits.sum()\n",
    "            smear_width = torch.sum(\n",
    "                logits_norm \n",
    "                * torch.tensor(dynamic_smear_width_embeds[1]).to(device)\n",
    "            ).item()\n",
    "            spread = torch.sum(\n",
    "                logits_norm \n",
    "                * torch.tensor(dynamic_smear_width_embeds[2]).to(device)\n",
    "            ).item()\n",
    "            print(smear_width, spread)\n",
    "            smear_width = max(round(smear_width), 1)\n",
    "            spread = max(round(spread), 1)\n",
    "            envelope = get_envelope(smear_width)\n",
    "                    \n",
    "        for smear_slot in range(-smear_width, smear_width+1):\n",
    "            for spread_slot in range(-spread, spread+1):\n",
    "                smeared_chunks[\n",
    "                    wrap(position_idx+smear_slot+spread_slot, num_chunks)\n",
    "                ] += (\n",
    "                        original_order_chunks_no_window[\n",
    "                            wrap(source_chunk_idx+spread_slot, num_chunks)]\n",
    "                        * envelope[smear_slot+smear_width] \n",
    "                        * (1/((spread+1)*smear_width))\n",
    "                )\n",
    "\n",
    "    for smeared_chunk in smeared_chunks:\n",
    "        yield smeared_chunk\n",
    "        \n",
    "    #for i \n",
    "smear_width = 1\n",
    "spread = 4\n",
    "smear_mode = 'in-out'\n",
    "\n",
    "dynamic_smear_width_defs = [('dreamy, mysterious, sparse', 6, 4), \n",
    "                            ('driving, rhythmic, instrumental, simple beat', 2, 2), \n",
    "                            ('intense, emotional, screaming, wailing', 1, 6)]\n",
    "print(tokenizer('stuff', padding=True, return_tensors='pt').input_ids)\n",
    "\n",
    "dynamic_smear_width_embeds = (\n",
    "    torch.concat([get_text_features(t) for t, _, _ in dynamic_smear_width_defs]),\n",
    "    [w for _, w, _ in dynamic_smear_width_defs],\n",
    "    [s for _, _, s in dynamic_smear_width_defs]\n",
    ")\n",
    "\n",
    "smeared_chunks = list(smear_2(stereo_chunks_no_window, sort_order=sort_order, smear_width=smear_width, spread=spread, smear_mode=smear_mode, \n",
    "                              dynamic_smear_width_embeds=dynamic_smear_width_embeds\n",
    "                              ))\n",
    "#print(Counter([len(c) for c in smeared_chunks]))\n",
    "smeared = torch.cat(smeared_chunks, dim=1)\n",
    "print(smeared.shape)\n",
    "torchaudio.save(filename + f'-sorted-norm-bpm{bpm}-cb{chunk_beats}-ww{window_width}-smeared-sm_{smear_mode}-sw{smear_width}-spread_actual{spread}-dyn3b.wav', smeared, sample_rate=sampling_rate)\n"
   ],
   "id": "9dba53f8186bff29"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
