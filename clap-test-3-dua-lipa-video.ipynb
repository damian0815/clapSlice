{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T09:36:22.828853Z",
     "start_time": "2025-07-04T09:36:15.179421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "!pip install datasets transformers librosa soundfile numpy\"<\"2 torch torchaudio fast-tsp kmedoids pytorchvideo torchvision torchcodec\n"
   ],
   "id": "b7880da606420f96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./venv/lib/python3.12/site-packages (3.6.0)\r\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.12/site-packages (4.52.4)\r\n",
      "Requirement already satisfied: librosa in ./venv/lib/python3.12/site-packages (0.11.0)\r\n",
      "Requirement already satisfied: soundfile in ./venv/lib/python3.12/site-packages (0.13.1)\r\n",
      "Requirement already satisfied: numpy<2 in ./venv/lib/python3.12/site-packages (1.26.4)\r\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.12/site-packages (2.2.1)\r\n",
      "Requirement already satisfied: torchaudio in ./venv/lib/python3.12/site-packages (2.2.1)\r\n",
      "Requirement already satisfied: fast-tsp in ./venv/lib/python3.12/site-packages (0.1.4)\r\n",
      "Requirement already satisfied: kmedoids in ./venv/lib/python3.12/site-packages (0.5.3.1)\r\n",
      "Requirement already satisfied: pytorchvideo in ./venv/lib/python3.12/site-packages (0.1.5)\r\n",
      "Requirement already satisfied: torchvision in ./venv/lib/python3.12/site-packages (0.17.1)\r\n",
      "Requirement already satisfied: torchcodec in ./venv/lib/python3.12/site-packages (0.0.0.dev0)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from datasets) (3.18.0)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./venv/lib/python3.12/site-packages (from datasets) (20.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./venv/lib/python3.12/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (from datasets) (2.3.0)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in ./venv/lib/python3.12/site-packages (from datasets) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./venv/lib/python3.12/site-packages (from datasets) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in ./venv/lib/python3.12/site-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./venv/lib/python3.12/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in ./venv/lib/python3.12/site-packages (from datasets) (2025.3.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./venv/lib/python3.12/site-packages (from datasets) (0.33.0)\r\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from datasets) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from datasets) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./venv/lib/python3.12/site-packages (from transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.12/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./venv/lib/python3.12/site-packages (from librosa) (3.0.1)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in ./venv/lib/python3.12/site-packages (from librosa) (0.61.2)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.15.3)\r\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.7.0)\r\n",
      "Requirement already satisfied: joblib>=1.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.5.1)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./venv/lib/python3.12/site-packages (from librosa) (5.2.1)\r\n",
      "Requirement already satisfied: pooch>=1.1 in ./venv/lib/python3.12/site-packages (from librosa) (1.8.2)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./venv/lib/python3.12/site-packages (from librosa) (0.5.0.post1)\r\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in ./venv/lib/python3.12/site-packages (from librosa) (4.14.0)\r\n",
      "Requirement already satisfied: lazy_loader>=0.1 in ./venv/lib/python3.12/site-packages (from librosa) (0.4)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.1.1)\r\n",
      "Requirement already satisfied: cffi>=1.0 in ./venv/lib/python3.12/site-packages (from soundfile) (1.17.1)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.12/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fvcore in ./venv/lib/python3.12/site-packages (from pytorchvideo) (0.1.5.post20221221)\r\n",
      "Requirement already satisfied: av in ./venv/lib/python3.12/site-packages (from pytorchvideo) (14.4.0)\r\n",
      "Requirement already satisfied: parameterized in ./venv/lib/python3.12/site-packages (from pytorchvideo) (0.9.0)\r\n",
      "Requirement already satisfied: iopath in ./venv/lib/python3.12/site-packages (from pytorchvideo) (0.1.10)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.12/site-packages (from torchvision) (11.2.1)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.12/site-packages (from cffi>=1.0->soundfile) (2.22)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./venv/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\r\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./venv/lib/python3.12/site-packages (from numba>=0.51.0->librosa) (0.44.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./venv/lib/python3.12/site-packages (from pooch>=1.1->librosa) (4.3.8)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\r\n",
      "Requirement already satisfied: yacs>=0.1.6 in ./venv/lib/python3.12/site-packages (from fvcore->pytorchvideo) (0.1.8)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in ./venv/lib/python3.12/site-packages (from fvcore->pytorchvideo) (3.1.0)\r\n",
      "Requirement already satisfied: tabulate in ./venv/lib/python3.12/site-packages (from fvcore->pytorchvideo) (0.9.0)\r\n",
      "Requirement already satisfied: portalocker in ./venv/lib/python3.12/site-packages (from iopath->pytorchvideo) (3.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "3cb23ac2-7d44-42dc-8acf-0df92184c026"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T13:27:19.456980Z",
     "start_time": "2025-07-05T13:26:33.795973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformers import ClapModel, ClapFeatureExtractor, AutoTokenizer\n",
    "\n",
    "device='mps'\n",
    "model = ClapModel.from_pretrained(\"laion/clap-htsat-unfused\", use_safetensors=True).to(device)\n",
    "feature_extractor: ClapFeatureExtractor = ClapFeatureExtractor.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"laion/clap-htsat-unfused\")\n"
   ],
   "id": "5a78d7169b407d7d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T13:27:19.526035Z",
     "start_time": "2025-07-05T13:27:19.482977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Generator\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def wrap(idx, total):\n",
    "    if idx < 0:\n",
    "        return total + idx\n",
    "    elif idx >= total:\n",
    "        return idx - total\n",
    "    else:\n",
    "        return idx\n",
    "    \n",
    "def get_audio_chunks(waveform, chunk_size_seconds: float=0.25, \n",
    "                     window_width: float=0, include_window: bool=True\n",
    "             ) -> Generator[torch.Tensor, None, None]:\n",
    "    if len(waveform.shape) != 1:\n",
    "        raise ValueError(\"waveform should have shape [num_samples]\")\n",
    "    chunk_size = int(8 * ((sampling_rate * chunk_size_seconds) // 8))\n",
    "    window_width_samples = int(chunk_size * window_width)\n",
    "    for offset in range(window_width_samples, waveform.shape[0]-window_width_samples, chunk_size):\n",
    "        if include_window:\n",
    "            start = wrap(offset-window_width_samples, waveform.shape[0])\n",
    "            end = wrap(offset+chunk_size+window_width_samples, waveform.shape[0])\n",
    "        else:\n",
    "            start = offset\n",
    "            end = offset + chunk_size\n",
    "        yield waveform[start:end]\n",
    "    \n",
    "\n",
    "def get_audio_features(waveform: torch.Tensor, sampling_rate):\n",
    "    inputs = feature_extractor(waveform, sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "    #print(inputs.keys())\n",
    "    audio_features = model.get_audio_features(input_features=inputs.input_features.to(device))\n",
    "    return audio_features / torch.norm(audio_features, p=2, dim=1, keepdim=True)\n",
    "\n",
    "def get_text_features(text: str):\n",
    "    inputs = tokenizer(text, padding=True, return_tensors='pt')\n",
    "    text_features =  model.get_text_features(input_ids = inputs.input_ids.to(device))\n",
    "    return text_features / torch.norm(text_features, p=2, dim=1, keepdim=True)\n"
   ],
   "id": "5b4b82f01c2ca14b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run",
   "id": "6d42f4e095b6da6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T13:27:45.291407Z",
     "start_time": "2025-07-05T13:27:19.541305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "filename = '/Users/damian/2.current/clapSlice/outputs/Dua Lipa - Be The One (Official Music Video).mp3-sorted-cs2.742857142857143-smeared-sw5-spread0.waw.mp3'\n",
    "waveform, sampling_rate = torchaudio.load(filename)\n",
    "chunk_beats = 4\n",
    "bpm = 87.5\n",
    "window_width = 0\n",
    "chunk_size_seconds = chunk_beats*60/bpm\n",
    "\n",
    "if sampling_rate != feature_extractor.sampling_rate:\n",
    "    resampler = T.Resample(sampling_rate,  feature_extractor.sampling_rate, dtype=waveform.dtype)\n",
    "    waveform, sampling_rate = resampler(waveform), feature_extractor.sampling_rate\n",
    "\n",
    "print(sampling_rate, waveform.shape, chunk_size_seconds)\n",
    "\n",
    "left_chunks_window = list(get_audio_chunks(waveform[0], chunk_size_seconds=chunk_size_seconds, window_width=window_width))[:-1]\n",
    "right_chunks_window = list(get_audio_chunks(waveform[1], chunk_size_seconds=chunk_size_seconds, window_width=window_width))[:-1]\n",
    "mono_chunks = [(left_chunks_window[i] + right_chunks_window[i]) / 2 for i in range(len(left_chunks_window))]\n",
    "\n",
    "left_chunks_no_window = list(get_audio_chunks(waveform[0], chunk_size_seconds=chunk_size_seconds, window_width=window_width, include_window=False))[:-1]\n",
    "right_chunks_no_window = list(get_audio_chunks(waveform[1], chunk_size_seconds=chunk_size_seconds, window_width=window_width, include_window=False))[:-1]\n",
    "stereo_chunks_no_window = [torch.stack([left_chunks_no_window[index], right_chunks_no_window[index]])\n",
    "    for index in range(len(left_chunks_no_window))]\n",
    "features_pickle_filename = filename + f'.clap-norm-bpm{bpm}-cb{chunk_beats}-ww{window_width}.pkl'\n",
    "if os.path.exists(features_pickle_filename):\n",
    "    with open(features_pickle_filename, 'rb') as f:\n",
    "        all_features = pickle.load(f)\n",
    "else:\n",
    "    all_features = torch.concat([get_audio_features(chunk, sampling_rate=sampling_rate) \n",
    "                             for chunk in tqdm(mono_chunks)])\n",
    "    with open(features_pickle_filename, 'wb') as f:\n",
    "        pickle.dump(all_features, f)\n"
   ],
   "id": "9707a03e43c2066d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[65210]: Class AVFFrameReceiver is implemented in both /Users/damian/2.current/clapSlice/venv/lib/python3.12/site-packages/av/.dylibs/libavdevice.61.3.100.dylib (0x130e213b0) and /usr/local/Cellar/ffmpeg/6.1_1/lib/libavdevice.60.3.100.dylib (0x193770378). One of the two will be used. Which one is undefined.\n",
      "objc[65210]: Class AVFAudioReceiver is implemented in both /Users/damian/2.current/clapSlice/venv/lib/python3.12/site-packages/av/.dylibs/libavdevice.61.3.100.dylib (0x130e21400) and /usr/local/Cellar/ffmpeg/6.1_1/lib/libavdevice.60.3.100.dylib (0x1937703c8). One of the two will be used. Which one is undefined.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 torch.Size([2, 9742544]) 2.742857142857143\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Remap",
   "id": "d9cc67c60388aec7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T13:27:45.931055Z",
     "start_time": "2025-07-05T13:27:45.698517Z"
    }
   },
   "cell_type": "code",
   "source": "from clap_slice import sort_tsp",
   "id": "154fc3254f4d1101",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T13:27:45.970992Z",
     "start_time": "2025-07-05T13:27:45.937843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "original_filename = '/Users/damian/2.current/clapSlice/outputs/Dua Lipa - Be The One (Official Music Video).mp3.clap-cs2.742857142857143.pkl'\n",
    "\n",
    "with open(original_filename, 'rb') as f:\n",
    "    original_all_features = pickle.load(f)\n",
    "original_all_features = original_all_features[:all_features.shape[0]]\n",
    "print(original_all_features.shape)"
   ],
   "id": "2b80910f9a1106d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([73, 512])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T07:23:32.700076Z",
     "start_time": "2025-07-05T07:23:30.523217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sort_order = sort_tsp(original_all_features)\n",
    "print(sort_order)"
   ],
   "id": "fd7bd1a544980ed4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing distance matrix\n",
      "computing route\n",
      "tensor([55, 27, 71, 53, 69, 25, 67, 23, 51, 22, 50, 66, 64, 48, 20, 49, 21, 65,\n",
      "        46, 18, 47, 19,  0,  1,  2,  3,  7,  6, 10, 11,  8,  4,  9,  5, 61, 63,\n",
      "        57, 59, 58, 60, 62, 56, 72, 34, 38, 36, 33, 37, 35, 39, 44, 16, 12, 40,\n",
      "        13, 41, 17, 45, 15, 43, 42, 14, 32, 31, 29, 28, 30, 68, 52, 24, 26, 70,\n",
      "        54])\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T07:23:50.272483Z",
     "start_time": "2025-07-05T07:23:50.222695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from clap_slice import get_distance_matrix\n",
    "remap_distance_matrix = get_distance_matrix(original_all_features, all_features)\n",
    "#remap_distance_matrix.cpu()"
   ],
   "id": "56f4afab6c1c437",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T07:23:52.322522Z",
     "start_time": "2025-07-05T07:23:52.231426Z"
    }
   },
   "cell_type": "code",
   "source": "torch.argmin(remap_distance_matrix, dim=1, keepdim=False)",
   "id": "4c144051de646d11",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([34, 34, 34, 32, 38, 46, 38, 31, 47, 47, 27, 27, 51, 53, 59, 59, 27, 27,\n",
       "         0, 16, 27, 27, 12, 27, 27, 25, 25, 27, 70, 70, 70, 70, 65, 65, 67, 63,\n",
       "        65, 65, 67, 27, 52, 53, 59, 59, 27, 27,  0,  0,  6, 27, 12,  6, 27, 27,\n",
       "        27, 27, 37, 37, 38, 38, 38, 38, 38, 38,  6, 27, 12, 27, 27, 27, 25, 27,\n",
       "        37], device='mps:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T08:07:30.796511Z",
     "start_time": "2025-07-05T08:07:26.829991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from clap_slice.hungarian import hungarian_algorithm\n",
    "assignment = hungarian_algorithm(remap_distance_matrix).int()\n",
    "assignment.shape, assignment.cpu()"
   ],
   "id": "c456b1e2e47120f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24e6b324ff124367889ef50f579e535a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stuck with 18/73 non-zero entries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([44, 2]),\n",
       " tensor([[ 0, 34],\n",
       "         [ 4, 38],\n",
       "         [ 7, 31],\n",
       "         [ 9, 47],\n",
       "         [ 8, 48],\n",
       "         [10, 27],\n",
       "         [13, 53],\n",
       "         [14, 59],\n",
       "         [16, 49],\n",
       "         [18,  0],\n",
       "         [22, 12],\n",
       "         [23, 14],\n",
       "         [26, 25],\n",
       "         [25, 26],\n",
       "         [28, 70],\n",
       "         [29, 69],\n",
       "         [30, 71],\n",
       "         [32, 65],\n",
       "         [34, 67],\n",
       "         [36, 66],\n",
       "         [37, 64],\n",
       "         [40, 52],\n",
       "         [48,  6],\n",
       "         [56, 37],\n",
       "         [60, 28],\n",
       "         [64,  7],\n",
       "         [65,  4],\n",
       "         [70, 24],\n",
       "         [72, 36],\n",
       "         [ 6, 29],\n",
       "         [12, 50],\n",
       "         [46,  1],\n",
       "         [47, 22],\n",
       "         [51,  3],\n",
       "         [55, 19],\n",
       "         [ 3, 32],\n",
       "         [17, 54],\n",
       "         [19, 15],\n",
       "         [27, 17],\n",
       "         [35, 61],\n",
       "         [61, 39],\n",
       "         [43, 57],\n",
       "         [ 5, 40],\n",
       "         [50,  8]], dtype=torch.int32))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T08:20:18.749563Z",
     "start_time": "2025-07-05T08:20:17.844675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "next = [None] * len(original_all_features)\n",
    "for original, arranged in assignment:\n",
    "    print(original, arranged)\n",
    "    try:\n",
    "        #print(arranged, assignment[:, 1], assignment[:, 1].tolist().index(arranged+1))\n",
    "        arranged_f_index = assignment[:, 1].tolist().index(arranged+1)\n",
    "        #print(arranged_f_index)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    next[original] = assignment[arranged_f_index, 0].item()\n",
    "print(next)\n",
    "\n",
    "#inverse_assignment = torch.argsort(assignment)\n",
    "hungarian_boost = 1 + torch.zeros_like(remap_distance_matrix)\n",
    "for a, b in enumerate(next):\n",
    "    if b is None:\n",
    "        continue\n",
    "    #print(a, b)\n",
    "    hungarian_boost[a, b] -= 1\n",
    "    #hungarian_boost[b, a] -= 1\n",
    "\n",
    "for a, b in assignment:\n",
    "    #if a == 0:\n",
    "    #    hungarian_boost[:, b] = 100\n",
    "    #    hungarian_boost[b, b] = 0\n",
    "    if b == 0:\n",
    "        hungarian_boost[:, a] = 1\n",
    "    #    #hungarian_boost[a, :] = -100\n",
    "    #    hungarian_boost[a, a] = 0\n",
    "    #    #hungarian_boost[]\n",
    "    #hungarian_boost[b, a] += 0.1\n",
    "hungarian_boost.cpu()\n"
   ],
   "id": "af52514e4579c371",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='mps:0', dtype=torch.int32) tensor(34, device='mps:0', dtype=torch.int32)\n",
      "tensor(4, device='mps:0', dtype=torch.int32) tensor(38, device='mps:0', dtype=torch.int32)\n",
      "tensor(7, device='mps:0', dtype=torch.int32) tensor(31, device='mps:0', dtype=torch.int32)\n",
      "tensor(9, device='mps:0', dtype=torch.int32) tensor(47, device='mps:0', dtype=torch.int32)\n",
      "tensor(8, device='mps:0', dtype=torch.int32) tensor(48, device='mps:0', dtype=torch.int32)\n",
      "tensor(10, device='mps:0', dtype=torch.int32) tensor(27, device='mps:0', dtype=torch.int32)\n",
      "tensor(13, device='mps:0', dtype=torch.int32) tensor(53, device='mps:0', dtype=torch.int32)\n",
      "tensor(14, device='mps:0', dtype=torch.int32) tensor(59, device='mps:0', dtype=torch.int32)\n",
      "tensor(16, device='mps:0', dtype=torch.int32) tensor(49, device='mps:0', dtype=torch.int32)\n",
      "tensor(18, device='mps:0', dtype=torch.int32) tensor(0, device='mps:0', dtype=torch.int32)\n",
      "tensor(22, device='mps:0', dtype=torch.int32) tensor(12, device='mps:0', dtype=torch.int32)\n",
      "tensor(23, device='mps:0', dtype=torch.int32) tensor(14, device='mps:0', dtype=torch.int32)\n",
      "tensor(26, device='mps:0', dtype=torch.int32) tensor(25, device='mps:0', dtype=torch.int32)\n",
      "tensor(25, device='mps:0', dtype=torch.int32) tensor(26, device='mps:0', dtype=torch.int32)\n",
      "tensor(28, device='mps:0', dtype=torch.int32) tensor(70, device='mps:0', dtype=torch.int32)\n",
      "tensor(29, device='mps:0', dtype=torch.int32) tensor(69, device='mps:0', dtype=torch.int32)\n",
      "tensor(30, device='mps:0', dtype=torch.int32) tensor(71, device='mps:0', dtype=torch.int32)\n",
      "tensor(32, device='mps:0', dtype=torch.int32) tensor(65, device='mps:0', dtype=torch.int32)\n",
      "tensor(34, device='mps:0', dtype=torch.int32) tensor(67, device='mps:0', dtype=torch.int32)\n",
      "tensor(36, device='mps:0', dtype=torch.int32) tensor(66, device='mps:0', dtype=torch.int32)\n",
      "tensor(37, device='mps:0', dtype=torch.int32) tensor(64, device='mps:0', dtype=torch.int32)\n",
      "tensor(40, device='mps:0', dtype=torch.int32) tensor(52, device='mps:0', dtype=torch.int32)\n",
      "tensor(48, device='mps:0', dtype=torch.int32) tensor(6, device='mps:0', dtype=torch.int32)\n",
      "tensor(56, device='mps:0', dtype=torch.int32) tensor(37, device='mps:0', dtype=torch.int32)\n",
      "tensor(60, device='mps:0', dtype=torch.int32) tensor(28, device='mps:0', dtype=torch.int32)\n",
      "tensor(64, device='mps:0', dtype=torch.int32) tensor(7, device='mps:0', dtype=torch.int32)\n",
      "tensor(65, device='mps:0', dtype=torch.int32) tensor(4, device='mps:0', dtype=torch.int32)\n",
      "tensor(70, device='mps:0', dtype=torch.int32) tensor(24, device='mps:0', dtype=torch.int32)\n",
      "tensor(72, device='mps:0', dtype=torch.int32) tensor(36, device='mps:0', dtype=torch.int32)\n",
      "tensor(6, device='mps:0', dtype=torch.int32) tensor(29, device='mps:0', dtype=torch.int32)\n",
      "tensor(12, device='mps:0', dtype=torch.int32) tensor(50, device='mps:0', dtype=torch.int32)\n",
      "tensor(46, device='mps:0', dtype=torch.int32) tensor(1, device='mps:0', dtype=torch.int32)\n",
      "tensor(47, device='mps:0', dtype=torch.int32) tensor(22, device='mps:0', dtype=torch.int32)\n",
      "tensor(51, device='mps:0', dtype=torch.int32) tensor(3, device='mps:0', dtype=torch.int32)\n",
      "tensor(55, device='mps:0', dtype=torch.int32) tensor(19, device='mps:0', dtype=torch.int32)\n",
      "tensor(3, device='mps:0', dtype=torch.int32) tensor(32, device='mps:0', dtype=torch.int32)\n",
      "tensor(17, device='mps:0', dtype=torch.int32) tensor(54, device='mps:0', dtype=torch.int32)\n",
      "tensor(19, device='mps:0', dtype=torch.int32) tensor(15, device='mps:0', dtype=torch.int32)\n",
      "tensor(27, device='mps:0', dtype=torch.int32) tensor(17, device='mps:0', dtype=torch.int32)\n",
      "tensor(35, device='mps:0', dtype=torch.int32) tensor(61, device='mps:0', dtype=torch.int32)\n",
      "tensor(61, device='mps:0', dtype=torch.int32) tensor(39, device='mps:0', dtype=torch.int32)\n",
      "tensor(43, device='mps:0', dtype=torch.int32) tensor(57, device='mps:0', dtype=torch.int32)\n",
      "tensor(5, device='mps:0', dtype=torch.int32) tensor(40, device='mps:0', dtype=torch.int32)\n",
      "tensor(50, device='mps:0', dtype=torch.int32) tensor(8, device='mps:0', dtype=torch.int32)\n",
      "[None, None, None, None, 61, None, None, 3, 16, 8, 60, None, None, 17, None, None, 12, None, 46, None, None, None, None, 19, None, 10, 25, None, 30, 28, None, None, 36, None, None, None, 34, 32, None, None, 13, None, None, None, None, None, None, None, 64, None, None, 65, None, None, None, None, 4, None, None, None, 6, 5, None, None, 50, None, None, None, None, None, 26, None, 56]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T08:20:22.661085Z",
     "start_time": "2025-07-05T08:20:20.137030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sort_order = sort_tsp(original_all_features, dist_matrix_offset=hungarian_boost)\n",
    "print(sort_order)"
   ],
   "id": "753f0b309a33b03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing distance matrix\n",
      "computing route\n",
      "tensor([ 0,  1,  2,  3,  4, 61,  5,  9,  8, 16, 12, 40, 13, 17, 45, 41, 14, 42,\n",
      "        39, 35, 37, 32, 36, 34, 38, 33, 27, 71, 53, 69, 25, 10, 60,  6, 11, 24,\n",
      "        52, 68, 26, 70, 54, 55, 21, 49, 65, 67, 23, 19, 47, 18, 46, 20, 48, 64,\n",
      "        50, 66, 22, 51, 44, 15, 43, 30, 28, 29, 31,  7, 57, 59, 58, 62, 56, 63,\n",
      "        72])\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T08:21:00.680209Z",
     "start_time": "2025-07-05T08:21:00.634991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_linear_assignment import batch_linear_assignment\n",
    "assignment = batch_linear_assignment(remap_distance_matrix.unsqueeze(0).cpu())\n",
    "print(assignment)"
   ],
   "id": "1ebdd22d0e7edf1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[35, 33, 34, 32, 29, 45, 30, 31, 48, 46, 47, 28, 51, 53, 60, 58, 49, 56,\n",
      "          1, 22,  4,  6,  9, 14, 25, 20, 21, 16, 72, 69, 71, 70, 63, 65, 68, 62,\n",
      "         66, 64, 67, 61, 52, 54, 59, 57, 50, 55,  2,  0,  8,  5, 10, 13, 27, 17,\n",
      "         23, 19, 37, 42, 40, 41, 39, 44, 38, 43,  7,  3, 11, 12, 26, 15, 24, 18,\n",
      "         36]])\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Video",
   "id": "183eba1c89470f32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T12:37:34.333019Z",
     "start_time": "2025-07-05T12:36:19.405549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "from pytorchvideo.data.encoded_video_pyav import EncodedVideoPyAV\n",
    "video_path = '/Users/damian/2.current/clapSlice/outputs/Dua Lipa - Be The One (Official Music Video) (1080p_25fps_H264-128kbit_AAC).mp4'\n",
    "video: EncodedVideoPyAV = EncodedVideo.from_path(video_path)\n"
   ],
   "id": "93ab1302eb4c189c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T13:26:26.741373Z",
     "start_time": "2025-07-05T13:26:26.242450Z"
    }
   },
   "cell_type": "code",
   "source": "float(video.duration) / chunk_size_seconds",
   "id": "dc73e9415e7af83e",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunk_size_seconds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28mfloat\u001B[39m(video.duration) / \u001B[43mchunk_size_seconds\u001B[49m\n",
      "\u001B[31mNameError\u001B[39m: name 'chunk_size_seconds' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T11:29:51.834203Z",
     "start_time": "2025-07-04T11:12:43.152119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fps = 25\n",
    "import av\n",
    "video_output = av.open(filename + '.mp4', 'w')\n",
    "stream = video_output.add_stream('h264', rate=fps)\n",
    "stream.width = 1920  # Set frame width\n",
    "stream.height = 1080  # Set frame height\n",
    "stream.pix_fmt = 'yuv444p'   # Select yuv444p pixel format (better quality than default yuv420p).\n",
    "stream.options = {'crf': '17'}  # Select low crf for high quality (the price is larger file size).\n",
    "\n",
    "inverse_assignment = torch.argsort(assignment[0])\n",
    "\n",
    "for target_index in tqdm(range(len(assignment[0]))):\n",
    "    source_index = inverse_assignment[target_index].item()\n",
    "    if assignment[0, source_index] < 0:\n",
    "        continue\n",
    "    chunk_start_s = source_index * chunk_size_seconds\n",
    "    chunk_end_s = chunk_start_s + chunk_size_seconds\n",
    "    #print(source_index, chunk_start_s, chunk_end_s)\n",
    "    video_data = video.get_clip(start_sec = chunk_start_s, end_sec = chunk_end_s)\n",
    "    #print(video_data['video'].shape)\n",
    "    video_frames = video_data['video']\n",
    "    for frame_index in tqdm(range(video_frames.shape[1]), leave=False):\n",
    "        frame_data = video_frames[:, frame_index].byte().permute(1, 2, 0)\n",
    "        #print(frame_data.shape, frame_data[0][0])\n",
    "        frame = av.VideoFrame.from_ndarray(frame_data.numpy(), format=\"rgb24\")\n",
    "        frame.pts = None\n",
    "        video_output.mux(stream.encode(frame))\n",
    "        del frame\n",
    "    del video_data\n",
    "\n",
    "video_output.close()\n"
   ],
   "id": "916e95e7cb9d4eeb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c1d9d9403264ac59f6bfa3a87687cbd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "090702b7205e4915ac24f6daf23cbdaf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3488d7de6124d2db573f1921a2b5a8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac5f62d2029b46bda101595087cf1c1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d68eb19b07648ba9f40143b5f86e5e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85878d6bda974ce39a8fc7703d683ade"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1c0b1a581c347c88b15aaea02cc74a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "875eaaccd8e446aeaaba2fbbb2d3b5e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a7ba4deb34e49968785fb4651d7a45e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88c572e988d04b60bc92b7e58c5e9bdd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf67bb12bc8448fbac5eddbf915d4a65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b606072ff26d4a41a51b58a2598dd423"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "430536ae049c4d04a38e5f6b843199e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6ae8ca50d3a41b383ee0571db07872b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a160a4f6e8cc488b904aa243b510b942"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "125cb5663043479dae0387f9a9bb421d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1eba935f09b941e688d9d77b3de8eba2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8f3ff5a15ad497db9e41a025fa79254"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53afe5234cd348d99d3dbe37b5ec2ffc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41e3d80f6c794d6285859128315c03e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5dc6c41022624fb8a549180690b16d7c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "140a43996dee436a893da3f02051a733"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75b74857107a4ddeaf3e5d712935948c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e47a60d3515440b6a2524e267f5d5c78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ecdc6b8fa33408c80892e1d92ffb500"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "508d2caec2894b06ac6ac76529005e3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b1fa59a573e4118aac1e5f6a1867e19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78183ba650a54f32aa38430c7bd3e1a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc694916dc134093a9f3953c49cc32d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5594b9b16d54cd6bad6c698be618f08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e5b7d604dae41cd8645e2ae1db6b6b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91f427efe2754e0b855d7a46a5d88ac8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b75667ebc4d34e9ea32bc192be76369f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e27ea09c73ee472489582378785329eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a985b31dd5204b0695706854b67ef404"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ede3a8995c0243029ad5fa3b78267a47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06f503588ef6422099eb3f4407ef4fdd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02eb6a3bf9d04cb5a886c5f9e8e51977"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8db27cad9b3745758ddcd83c4a5e98af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24e055c124184afdb00a9bfe1869d872"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f25d634f99c45c78f498826d986d278"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42eb293b0983439d984d0c53c7cb0674"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e6eabf6ae034396806e2162f17624b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6271db1125bd43939f4bc0abd50433fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "405c1ed594a54f41b472db7469a44e75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1660ece740b14c4a9dc6be3f5b14dcc0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72ab8fa3ea684740a3359697fa29f134"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "196fe3b395ba4dda9e53e7c2340aba63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee617b3eea5d4ea790d486c690aad12c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "324a802e8679487b949b909c27d93bee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f11e32486024c69954f2528d596d840"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0f7dd186749433cb5239a26a01e84e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3fee382d8ce14d58b13d257a6bc6b864"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2eba3116a2084b3db073a3127c8db162"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "551deaec148e493cb992549414e4cd42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b7654b5ec36434db406385e84e4d668"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "410824fc67b549e0ba7eff992220ddc1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6c66e82fd274d07b3f5cf192b70d890"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26aad869dfef40d9b6e7876adacdd707"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "889d71d6db744aa1b55da4b4bcd22715"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bd35ca1cb4b47609e457552aa245fc7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "774eade4b24b49aa8412f2135f44a193"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b234c090a6d446a3a0fefc244ecb3736"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f261a57079e6424aacca58fc4a6d6ad7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "003a82ecd6ed4774b09bb98d944b5015"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c513e254b961444d8be98bec6f2b1f31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5084ae8c367435f8f05e4e3de7f9197"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85bc6df25f5d48a283fcdc0124f856f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdb0282c69744a1e8f10a09ed84dbf7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4c22f5db2e54e2faaf4f69e03b6d3af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64ce88b6f8e64eb08392dd64b0c6082c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e2f78c7e018418ab68646bb27ca0c60"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "110eee1c84fc4b178bd37f5f2d4fc9e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bd548fe6e4244a0ba0a9b257f4468dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T09:58:02.143148Z",
     "start_time": "2025-07-04T09:58:02.101763Z"
    }
   },
   "cell_type": "code",
   "source": "print(float(video.duration))",
   "id": "92b7041cb00f7abc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252288/11025\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T09:55:33.525701Z",
     "start_time": "2025-07-04T09:55:33.463269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "assignment[0], torch.unique(assignment[0])[1:] == torch.arange(len(assignment[0])-1)"
   ],
   "id": "36e943b87dad48ec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([35, 33, 34, 32, 29, 45, 30, 31, 48, 46, 47, 28, 51, 53, 60, 58, 49, 56,\n",
       "          1, 22,  4,  6,  9, 14, 25, 20, 21, 16, 72, 69, 71, 70, 63, 65, 68, 62,\n",
       "         66, 64, 67, 61, 52, 54, 59, 57, 50, 55,  2,  0,  8,  5, 10, 13, 27, 17,\n",
       "         23, 19, 37, 42, 40, 41, 39, 44, 38, 43,  7,  3, 11, 12, 26, 15, 24, 18,\n",
       "         36, -1]),\n",
       " tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T07:25:03.309664Z",
     "start_time": "2025-07-05T07:25:03.204217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inverse_assignment = torch.argsort(assignment[0])\n",
    "inverse_assignment"
   ],
   "id": "bd9bd412ca89f30",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([47, 18, 46, 65, 20, 49, 21, 64, 48, 22, 50, 66, 67, 51, 23, 69, 27, 53,\n",
       "        71, 55, 25, 26, 19, 54, 70, 24, 68, 52, 11,  4,  6,  7,  3,  1,  2,  0,\n",
       "        72, 56, 62, 60, 58, 59, 57, 63, 61,  5,  9, 10,  8, 16, 44, 12, 40, 13,\n",
       "        41, 45, 17, 43, 15, 42, 14, 39, 35, 32, 37, 33, 36, 38, 34, 29, 31, 30,\n",
       "        28])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T09:49:41.040517Z",
     "start_time": "2025-07-04T09:49:40.936108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.tensor([0, 4, 2, 1, 3])\n",
    "torch.argsort(a)"
   ],
   "id": "f3a090e7532c1220",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 2, 4, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T09:59:34.191969Z",
     "start_time": "2025-07-04T09:59:32.714488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clip_start_sec = 0.0 # secs\n",
    "clip_duration = 2.0 # secs\n",
    "video_data = video.get_clip(start_sec=clip_start_sec, end_sec=clip_start_sec + clip_duration)"
   ],
   "id": "dc7c8f7395c480c3",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T09:59:35.794944Z",
     "start_time": "2025-07-04T09:59:35.747888Z"
    }
   },
   "cell_type": "code",
   "source": "video_data['video'].shape",
   "id": "2feb8451631c1cd0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 50, 1080, 1920])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T17:02:27.183440Z",
     "start_time": "2025-07-04T17:01:35.434796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tracemalloc\n",
    "from tqdm.auto import tqdm\n",
    "try:\n",
    "    tracemalloc.start()\n",
    "    print(\"start:\", torch.mps.current_allocated_memory()/(1024*1024), tracemalloc.get_traced_memory()[0]/(1024*1024))\n",
    "    video_chunks = [None] * len(assignment[0])\n",
    "    for source_index, target_index in enumerate(tqdm(assignment[0])):\n",
    "        chunk_start_s = source_index * chunk_size_seconds\n",
    "        chunk_end_s = chunk_start_s + chunk_size_seconds\n",
    "        video_data = video.get_clip(start_sec = chunk_start_s, end_sec = chunk_end_s)\n",
    "        video_chunks[target_index] = video_data['video'].byte()\n",
    "        print(\"after chunk\", source_index, \":\", torch.mps.current_allocated_memory()/(1024*1024), tracemalloc.get_traced_memory()[0]/(1024*1024))\n",
    "        del video_data\n",
    "finally:\n",
    "    tracemalloc.stop()\n"
   ],
   "id": "a3e7179f6ad5efef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 587.101806640625 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c67058c6c2b04fb99a78d34bd3cea543"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after chunk 0 : 587.101806640625 0.6500930786132812\n",
      "after chunk 1 : 587.101806640625 0.6857318878173828\n",
      "after chunk 2 : 587.101806640625 0.7408819198608398\n",
      "after chunk 3 : 587.101806640625 0.6764802932739258\n",
      "after chunk 4 : 587.101806640625 0.7214689254760742\n",
      "after chunk 5 : 587.101806640625 0.7545967102050781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mmco: unref short failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after chunk 6 : 587.101806640625 0.8030595779418945\n",
      "after chunk 7 : 587.101806640625 0.8352193832397461\n",
      "after chunk 8 : 587.101806640625 0.7493391036987305\n",
      "after chunk 9 : 587.101806640625 0.788111686706543\n",
      "after chunk 10 : 587.101806640625 0.8159360885620117\n",
      "after chunk 11 : 587.101806640625 0.869598388671875\n",
      "after chunk 12 : 587.101806640625 0.8976469039916992\n",
      "after chunk 13 : 587.101806640625 0.7922000885009766\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[54]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      8\u001B[39m chunk_start_s = source_index * chunk_size_seconds\n\u001B[32m      9\u001B[39m chunk_end_s = chunk_start_s + chunk_size_seconds\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m video_data = \u001B[43mvideo\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_clip\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstart_sec\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk_start_s\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_sec\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk_end_s\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m video_chunks[target_index] = video_data[\u001B[33m'\u001B[39m\u001B[33mvideo\u001B[39m\u001B[33m'\u001B[39m].byte()\n\u001B[32m     12\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mafter chunk\u001B[39m\u001B[33m\"\u001B[39m, source_index, \u001B[33m\"\u001B[39m\u001B[33m:\u001B[39m\u001B[33m\"\u001B[39m, torch.mps.current_allocated_memory()/(\u001B[32m1024\u001B[39m*\u001B[32m1024\u001B[39m), tracemalloc.get_traced_memory()[\u001B[32m0\u001B[39m]/(\u001B[32m1024\u001B[39m*\u001B[32m1024\u001B[39m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/2.current/clapSlice/venv/lib/python3.12/site-packages/pytorchvideo/data/encoded_video_pyav.py:202\u001B[39m, in \u001B[36mEncodedVideoPyAV.get_clip\u001B[39m\u001B[34m(self, start_sec, end_sec)\u001B[39m\n\u001B[32m    199\u001B[39m     video_frames = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    201\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m video_frames \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m202\u001B[39m     video_frames = thwc_to_cthw(\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvideo_frames\u001B[49m\u001B[43m)\u001B[49m).to(torch.float32)\n\u001B[32m    204\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m    205\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mvideo\u001B[39m\u001B[33m\"\u001B[39m: video_frames,\n\u001B[32m    206\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33maudio\u001B[39m\u001B[33m\"\u001B[39m: audio_samples,\n\u001B[32m    207\u001B[39m }\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T17:02:31.532058Z",
     "start_time": "2025-07-04T17:02:31.489166Z"
    }
   },
   "cell_type": "code",
   "source": "tracemalloc.get_traced_memory()",
   "id": "3e046f81db5a866a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T16:59:14.139088Z",
     "start_time": "2025-07-04T16:59:13.611348Z"
    }
   },
   "cell_type": "code",
   "source": "del video_chunks",
   "id": "e3eab8c83dbee63b",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T09:30:49.862153Z",
     "start_time": "2025-07-04T09:30:49.814809Z"
    }
   },
   "cell_type": "code",
   "source": "assignment.shape",
   "id": "eb48259d0314601a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 74])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "51a7e31530bf44a9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
