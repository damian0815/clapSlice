{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T12:01:00.350842Z",
     "start_time": "2025-06-22T12:00:54.864896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "!pip install datasets transformers librosa soundfile numpy\"<\"2 torch torchaudio fast-tsp kmedoids\n"
   ],
   "id": "b7880da606420f96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./venv/lib/python3.12/site-packages (3.6.0)\r\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.12/site-packages (4.52.4)\r\n",
      "Requirement already satisfied: librosa in ./venv/lib/python3.12/site-packages (0.11.0)\r\n",
      "Requirement already satisfied: soundfile in ./venv/lib/python3.12/site-packages (0.13.1)\r\n",
      "Requirement already satisfied: numpy<2 in ./venv/lib/python3.12/site-packages (1.26.4)\r\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.12/site-packages (2.2.1)\r\n",
      "Requirement already satisfied: torchaudio in ./venv/lib/python3.12/site-packages (2.2.1)\r\n",
      "Requirement already satisfied: fast-tsp in ./venv/lib/python3.12/site-packages (0.1.4)\r\n",
      "Collecting kmedoids\r\n",
      "  Obtaining dependency information for kmedoids from https://files.pythonhosted.org/packages/6e/b4/457e552aa362cc746fbf0c461ab1a9bd7794db3321f82586601769f27112/kmedoids-0.5.3.1-cp312-cp312-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata\r\n",
      "  Downloading kmedoids-0.5.3.1-cp312-cp312-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (9.6 kB)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from datasets) (3.18.0)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./venv/lib/python3.12/site-packages (from datasets) (20.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./venv/lib/python3.12/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (from datasets) (2.3.0)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in ./venv/lib/python3.12/site-packages (from datasets) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./venv/lib/python3.12/site-packages (from datasets) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in ./venv/lib/python3.12/site-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./venv/lib/python3.12/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in ./venv/lib/python3.12/site-packages (from datasets) (2025.3.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./venv/lib/python3.12/site-packages (from datasets) (0.33.0)\r\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from datasets) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from datasets) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./venv/lib/python3.12/site-packages (from transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.12/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./venv/lib/python3.12/site-packages (from librosa) (3.0.1)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in ./venv/lib/python3.12/site-packages (from librosa) (0.61.2)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.15.3)\r\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.7.0)\r\n",
      "Requirement already satisfied: joblib>=1.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.5.1)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./venv/lib/python3.12/site-packages (from librosa) (5.2.1)\r\n",
      "Requirement already satisfied: pooch>=1.1 in ./venv/lib/python3.12/site-packages (from librosa) (1.8.2)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./venv/lib/python3.12/site-packages (from librosa) (0.5.0.post1)\r\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in ./venv/lib/python3.12/site-packages (from librosa) (4.14.0)\r\n",
      "Requirement already satisfied: lazy_loader>=0.1 in ./venv/lib/python3.12/site-packages (from librosa) (0.4)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.1.1)\r\n",
      "Requirement already satisfied: cffi>=1.0 in ./venv/lib/python3.12/site-packages (from soundfile) (1.17.1)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.12/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.12/site-packages (from cffi>=1.0->soundfile) (2.22)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./venv/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\r\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./venv/lib/python3.12/site-packages (from numba>=0.51.0->librosa) (0.44.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./venv/lib/python3.12/site-packages (from pooch>=1.1->librosa) (4.3.8)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
      "Downloading kmedoids-0.5.3.1-cp312-cp312-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (915 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m915.7/915.7 kB\u001B[0m \u001B[31m9.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hInstalling collected packages: kmedoids\r\n",
      "Successfully installed kmedoids-0.5.3.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "3cb23ac2-7d44-42dc-8acf-0df92184c026",
   "metadata": {},
   "source": "# Setup"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T17:40:34.985001Z",
     "start_time": "2025-06-22T17:40:27.760348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformers import ClapModel, ClapFeatureExtractor, AutoTokenizer\n",
    "\n",
    "device='mps'\n",
    "model = ClapModel.from_pretrained(\"laion/clap-htsat-unfused\", use_safetensors=True).to(device)\n",
    "feature_extractor: ClapFeatureExtractor = ClapFeatureExtractor.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"laion/clap-htsat-unfused\")\n"
   ],
   "id": "5a78d7169b407d7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2140581632c643ff83bf2bba9da6f574"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05ba6b97c3be4251bc4748756481e07d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4aebbb4bd8274d9eb1bee62877b2939b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be529026c87b48fa8813ae2c22e9c899"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "874d35bd1f5845e5a2ca23af624b338f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run",
   "id": "6d42f4e095b6da6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:18:47.078466Z",
     "start_time": "2025-06-22T19:18:45.756807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "filename = '/Users/damian/Downloads/Dua Lipa - Be The One (Official Music Video).mp3'\n",
    "waveform, sampling_rate = torchaudio.load(filename)\n",
    "chunk_beats = 2\n",
    "bpm = 87.5\n",
    "window_width = 0\n",
    "\n",
    "if sampling_rate != feature_extractor.sampling_rate:\n",
    "    resampler = T.Resample(sampling_rate,  feature_extractor.sampling_rate, dtype=waveform.dtype)\n",
    "    waveform, sampling_rate = resampler(waveform), feature_extractor.sampling_rate\n",
    "\n",
    "print(sampling_rate, waveform.shape)\n",
    "#inputs = feature_extractor(waveform, sampling_rate=sample_rate, return_tensors=\"pt\")\n",
    "#audio_features = model.get_audio_features(**inputs)"
   ],
   "id": "d5d30b5e7ea5cb98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 torch.Size([2, 9805880])\n"
     ]
    }
   ],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:18:47.170224Z",
     "start_time": "2025-06-22T19:18:47.096197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Generator\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def wrap(idx, total):\n",
    "    if idx < 0:\n",
    "        return total + idx\n",
    "    elif idx >= total:\n",
    "        return idx - total\n",
    "    else:\n",
    "        return idx\n",
    "    \n",
    "def get_audio_chunks(waveform, chunk_size_seconds: float=0.25, \n",
    "                     window_width: float=0, include_window: bool=True\n",
    "             ) -> Generator[torch.Tensor, None, None]:\n",
    "    if len(waveform.shape) != 1:\n",
    "        raise ValueError(\"waveform should have shape [num_samples]\")\n",
    "    chunk_size = int(8 * ((sampling_rate * chunk_size_seconds) // 8))\n",
    "    window_width_samples = int(chunk_size * window_width)\n",
    "    for offset in range(window_width_samples, waveform.shape[0]-window_width_samples, chunk_size):\n",
    "        if include_window:\n",
    "            start = wrap(offset-window_width_samples, waveform.shape[0])\n",
    "            end = wrap(offset+chunk_size+window_width_samples, waveform.shape[0])\n",
    "        else:\n",
    "            start = offset\n",
    "            end = offset + chunk_size\n",
    "        yield waveform[start:end]\n",
    "    \n",
    "\n",
    "def get_audio_features(waveform: torch.Tensor, sampling_rate):\n",
    "    inputs = feature_extractor(waveform, sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "    #print(inputs.keys())\n",
    "    audio_features = model.get_audio_features(input_features=inputs.input_features.to(device))\n",
    "    return audio_features / torch.norm(audio_features, p=2, dim=1, keepdim=True)\n",
    "\n",
    "def get_text_features(text: str):\n",
    "    inputs = tokenizer(text, padding=True, return_tensors='pt')\n",
    "    text_features =  model.get_text_features(input_ids = inputs.input_ids.to(device))\n",
    "    return text_features / torch.norm(text_features, p=2, dim=1, keepdim=True)\n"
   ],
   "id": "5b4b82f01c2ca14b",
   "outputs": [],
   "execution_count": 199
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:18:47.678266Z",
     "start_time": "2025-06-22T19:18:47.538276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "chunk_size_seconds = chunk_beats*60/bpm\n",
    "left_chunks_window = list(get_audio_chunks(waveform[0], chunk_size_seconds=chunk_size_seconds, window_width=window_width))[:-1]\n",
    "right_chunks_window = list(get_audio_chunks(waveform[1], chunk_size_seconds=chunk_size_seconds, window_width=window_width))[:-1]\n",
    "mono_chunks = [(left_chunks_window[i] + right_chunks_window[i]) / 2 for i in range(len(left_chunks_window))]\n",
    "\n",
    "left_chunks_no_window = list(get_audio_chunks(waveform[0], chunk_size_seconds=chunk_size_seconds, window_width=window_width, include_window=False))[:-1]\n",
    "right_chunks_no_window = list(get_audio_chunks(waveform[1], chunk_size_seconds=chunk_size_seconds, window_width=window_width, include_window=False))[:-1]\n",
    "stereo_chunks_no_window = [torch.stack([left_chunks_no_window[index], right_chunks_no_window[index]])\n",
    "    for index in range(len(left_chunks_no_window))]\n",
    "features_pickle_filename = filename + f'.clap-norm-bpm{bpm}-cb{chunk_beats}-ww{window_width}.pkl'\n",
    "if os.path.exists(features_pickle_filename):\n",
    "    with open(features_pickle_filename, 'rb') as f:\n",
    "        all_features = pickle.load(f)\n",
    "else:\n",
    "    all_features = torch.concat([get_audio_features(chunk, sampling_rate=sampling_rate) \n",
    "                             for chunk in tqdm(mono_chunks)])\n",
    "    with open(features_pickle_filename, 'wb') as f:\n",
    "        pickle.dump(all_features, f)\n",
    "\n"
   ],
   "id": "c691f5b529b7e6c9",
   "outputs": [],
   "execution_count": 200
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:18:51.223948Z",
     "start_time": "2025-06-22T19:18:48.195701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.clap_slice.medoids_tsp import sort_tsp\n",
    "sort_order = sort_tsp(all_features)"
   ],
   "id": "b6a9e3a09263202d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing distance matrix\n",
      "computing route\n"
     ]
    }
   ],
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:18:51.554789Z",
     "start_time": "2025-06-22T19:18:51.228636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chunks_sorted = [torch.stack([left_chunks_no_window[index], right_chunks_no_window[index]])\n",
    "    for index in sort_order]\n",
    "print(chunks_sorted[0].shape)\n",
    "sorted_audio = torch.cat(chunks_sorted, dim=1)\n",
    "print(sorted_audio.shape)"
   ],
   "id": "87f9d40beaf70379",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 65824])\n",
      "torch.Size([2, 9741952])\n"
     ]
    }
   ],
   "execution_count": 202
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"sort_order = torch.tensor([ 96,  40, 128, 123, 115, 127,  83,  27,  31,  87,  71,  67,  75, 100,\n",
    "         44, 102,  46, 134, 132,  51, 139, 107, 111,  55, 143,  43, 131,  99,\n",
    "         41,  97, 129, 101, 133,  45,  47, 103, 135, 136, 104,  48, 140, 108,\n",
    "         52, 110,  54, 106,  50, 138, 105,  49, 137, 109, 141,  53, 142,  78,\n",
    "         77,  69,  85,  29,  30,  86,  70,  59,  63,  65,  64,  72,  74,  66,\n",
    "         76,  68,  73,  56,  60,  61,  57,  62,  58,  21,  22,  13,  14,  39,\n",
    "         95,  38,  94,  93,  37, 144, 147, 146, 145,   0,   3,   4,   6,   5,\n",
    "          2,   1,   7,  15,  16,  17,  20,  12,  10,   8,   9,  18, 122, 126,\n",
    "         19,  11, 119, 116, 124, 120, 125, 121, 117, 118, 114, 113, 112,  92,\n",
    "         36,  23,  79,  89,  81,  25,  33,  32,  88,  24,  80,  90,  34,  82,\n",
    "         26,  28,  84,  35,  91, 130,  42,  98])\"\"\"\n",
    "None"
   ],
   "id": "4c251f0bcabb14a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:18:51.634370Z",
     "start_time": "2025-06-22T19:18:51.558209Z"
    }
   },
   "cell_type": "code",
   "source": "sort_order",
   "id": "7a3153fb417164b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 96,  40, 128, 123, 115, 127,  83,  27,  31,  87,  71,  67,  75, 100,\n",
       "         44, 102,  46, 134, 132,  51, 139, 107, 111,  55, 143,  43, 131,  99,\n",
       "         41,  97, 129, 101, 133,  45,  47, 103, 135, 136, 104,  48, 140, 108,\n",
       "         52, 110,  54, 106,  50, 138, 105,  49, 137, 109, 141,  53, 142,  78,\n",
       "         77,  69,  85,  29,  30,  86,  70,  59,  63,  65,  64,  72,  74,  66,\n",
       "         76,  68,  73,  56,  60,  61,  57,  62,  58,  21,  22,  13,  14,  39,\n",
       "         95,  38,  94,  93,  37, 144, 147, 146, 145,   0,   3,   4,   6,   5,\n",
       "          2,   1,   7,  15,  16,  17,  20,  12,  10,   8,   9,  18, 122, 126,\n",
       "         19,  11, 119, 116, 124, 120, 125, 121, 117, 118, 114, 113, 112,  92,\n",
       "         36,  23,  79,  89,  81,  25,  33,  32,  88,  24,  80,  90,  34,  82,\n",
       "         26,  28,  84,  35,  91, 130,  42,  98])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:18:53.291394Z",
     "start_time": "2025-06-22T19:18:51.641317Z"
    }
   },
   "cell_type": "code",
   "source": "torchaudio.save(filename + f'-sorted-norm-bpm{bpm}-cb{chunk_beats}-ww{window_width}.wav', sorted_audio, sample_rate=sampling_rate)",
   "id": "7350c7926c1c6c7b",
   "outputs": [],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:19:05.355151Z",
     "start_time": "2025-06-22T19:18:53.294182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "def smear(chunks, smear_width):\n",
    "    envelope = 0.5*(1-torch.cos(torch.linspace(0, 2*math.pi, 2*smear_width+1)))\n",
    "    #for i in range(smear_width+1, 2*smear_width+1):\n",
    "    #    envelope[i] = 0\n",
    "    print(envelope)\n",
    "    for i in range(len(chunks)-smear_width*2-1):\n",
    "        smear_sources = [\n",
    "            chunks[i+chunk_index] * envelope[chunk_index]\n",
    "            #(i+chunk_index, envelope[chunk_index])\n",
    "            for chunk_index in range(0, min(len(chunks), smear_width*2+1))\n",
    "        ]\n",
    "        #print(smear_sources)\n",
    "        #print(set([ss.shape for ss in smear_sources]))\n",
    "        #print(torch.sum(torch.stack(smear_sources), dim=0))\n",
    "        smeared_chunk = torch.sum(torch.stack(smear_sources), dim=0) / len(smear_sources)\n",
    "        #print(smeared_chunk.shape)\n",
    "        #break\n",
    "        yield smeared_chunk\n",
    "        \n",
    "def smear_2(original_order_chunks_no_window, sort_order, smear_width, spread=4, \n",
    "            smear_mode=Literal['in', 'in-out'],\n",
    "            dynamic_smear_width_embeds: tuple[torch.Tensor, list[int]]=None):\n",
    "    \n",
    "    def get_envelope(smear_width):\n",
    "        envelope = 0.5*(1-torch.cos(torch.linspace(0, 2*math.pi, 2*smear_width+1)))\n",
    "        if smear_mode == 'in':\n",
    "            for i in range(smear_width+1, 2*smear_width+1):\n",
    "                envelope[i] = 0\n",
    "        return envelope\n",
    "    envelope = get_envelope(smear_width)\n",
    "    print(envelope)\n",
    "    num_chunks = len(original_order_chunks_no_window)\n",
    "    smeared_chunks = [torch.zeros_like(original_order_chunks_no_window[0]) \n",
    "                     for _ in range(num_chunks)]\n",
    "    for position_idx in tqdm(range(num_chunks), total=num_chunks):\n",
    "        source_chunk_idx = sort_order[position_idx]\n",
    "        \n",
    "        if dynamic_smear_width_embeds is not None:\n",
    "            source_chunk_embed = all_features[source_chunk_idx]\n",
    "            logits = source_chunk_embed @ dynamic_smear_width_embeds[0].T\n",
    "            #print(logits)\n",
    "            #print(logits.softmax(dim=0))\n",
    "            smear_width = torch.sum((logits / logits.sum()) \n",
    "                                              * torch.tensor(dynamic_smear_width_embeds[1]).to(device)).item()\n",
    "            print(smear_width)\n",
    "            smear_width = max(round(smear_width), 1)\n",
    "            envelope = get_envelope(smear_width)\n",
    "                    \n",
    "        for smear_slot in range(-smear_width, smear_width+1):\n",
    "            for spread_slot in range(-spread, spread+1):\n",
    "                smeared_chunks[\n",
    "                    wrap(position_idx+smear_slot+spread_slot, num_chunks)\n",
    "                ] += (\n",
    "                        original_order_chunks_no_window[\n",
    "                            wrap(source_chunk_idx+spread_slot, num_chunks)]\n",
    "                        * envelope[smear_slot+smear_width] \n",
    "                        * (1/((spread+1)*smear_width))\n",
    "                )\n",
    "\n",
    "    for smeared_chunk in smeared_chunks:\n",
    "        yield smeared_chunk\n",
    "        \n",
    "    #for i \n",
    "smear_width = 1\n",
    "spread = 4\n",
    "smear_mode = 'in-out'\n",
    "\n",
    "dynamic_smear_width_defs = [('dreamy, mysterious, sparse', 6), ('intense, emotional, screaming, wailing', 1)]\n",
    "print(tokenizer('stuff', padding=True, return_tensors='pt').input_ids)\n",
    "\n",
    "dynamic_smear_width_embeds = (\n",
    "    torch.concat([get_text_features(s) for s, _ in dynamic_smear_width_defs]),\n",
    "    [w for _, w in dynamic_smear_width_defs]\n",
    ")\n",
    "\n",
    "smeared_chunks = list(smear_2(stereo_chunks_no_window, sort_order=sort_order, smear_width=smear_width, spread=spread, smear_mode=smear_mode, \n",
    "                              dynamic_smear_width_embeds=dynamic_smear_width_embeds\n",
    "                              ))\n",
    "#print(Counter([len(c) for c in smeared_chunks]))\n",
    "smeared = torch.cat(smeared_chunks, dim=1)\n",
    "print(smeared.shape)\n",
    "torchaudio.save(filename + f'-sorted-norm-bpm{bpm}-cb{chunk_beats}-ww{window_width}-smeared-sm_{smear_mode}-sw{smear_width}-spread_actual{spread}-dyn2.wav', smeared, sample_rate=sampling_rate)\n"
   ],
   "id": "2e343d37b2782fd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0, 40110,     2]])\n",
      "tensor([0., 1., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4059625fb2d94b3c8d3aa0ece71904d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.025988817214966\n",
      "2.9852519035339355\n",
      "3.2653768062591553\n",
      "2.4126291275024414\n",
      "2.916337251663208\n",
      "2.4362034797668457\n",
      "2.5560402870178223\n",
      "2.888916015625\n",
      "3.590606689453125\n",
      "2.3081581592559814\n",
      "4.081085205078125\n",
      "7.580249309539795\n",
      "-10.736671447753906\n",
      "4.112405776977539\n",
      "3.9278945922851562\n",
      "3.7751708030700684\n",
      "5.042652130126953\n",
      "4.152952671051025\n",
      "4.365510940551758\n",
      "3.928717613220215\n",
      "4.462410926818848\n",
      "4.296231269836426\n",
      "2.9200239181518555\n",
      "3.811128616333008\n",
      "3.860072374343872\n",
      "4.524397850036621\n",
      "4.241306781768799\n",
      "3.9809253215789795\n",
      "3.981428623199463\n",
      "3.6327860355377197\n",
      "3.5670528411865234\n",
      "3.513566493988037\n",
      "3.828505754470825\n",
      "4.05603551864624\n",
      "3.862551689147949\n",
      "4.121306896209717\n",
      "4.595206260681152\n",
      "4.924497127532959\n",
      "5.14949369430542\n",
      "4.538237571716309\n",
      "5.245449066162109\n",
      "4.736452102661133\n",
      "4.827077388763428\n",
      "4.4414873123168945\n",
      "5.3326416015625\n",
      "5.198671340942383\n",
      "5.352368354797363\n",
      "6.101564884185791\n",
      "5.535776615142822\n",
      "5.547762393951416\n",
      "6.531044006347656\n",
      "6.016571044921875\n",
      "5.717024326324463\n",
      "9.459341049194336\n",
      "6.713302135467529\n",
      "92.47554016113281\n",
      "-18.09341812133789\n",
      "-9.406277656555176\n",
      "37.468971252441406\n",
      "-248.74813842773438\n",
      "18.73008155822754\n",
      "19.762712478637695\n",
      "-12.974860191345215\n",
      "15.302400588989258\n",
      "10.54151439666748\n",
      "9.8550443649292\n",
      "7.575802326202393\n",
      "10.358927726745605\n",
      "62.56718444824219\n",
      "-22.12334442138672\n",
      "11.399238586425781\n",
      "12.318931579589844\n",
      "11.347225189208984\n",
      "7.218570232391357\n",
      "5.978060722351074\n",
      "98.19186401367188\n",
      "-32.721168518066406\n",
      "19.874298095703125\n",
      "128.6183319091797\n",
      "17.973295211791992\n",
      "18.560176849365234\n",
      "20.125972747802734\n",
      "17.17681312561035\n",
      "8.084563255310059\n",
      "6.8807373046875\n",
      "7.616970062255859\n",
      "7.026700496673584\n",
      "6.783227443695068\n",
      "7.654159069061279\n",
      "7.146003246307373\n",
      "5.711408615112305\n",
      "9.916825294494629\n",
      "16.958797454833984\n",
      "18.925735473632812\n",
      "12.487083435058594\n",
      "11.56155014038086\n",
      "14.003523826599121\n",
      "-43.551448822021484\n",
      "12.693294525146484\n",
      "14.788995742797852\n",
      "4.841163158416748\n",
      "13.253954887390137\n",
      "7.2018141746521\n",
      "6.911979675292969\n",
      "9.888895034790039\n",
      "8.839164733886719\n",
      "6.6463775634765625\n",
      "7.988178253173828\n",
      "5.604240417480469\n",
      "4.545772075653076\n",
      "5.713470458984375\n",
      "3.4767136573791504\n",
      "3.8424530029296875\n",
      "2.587162971496582\n",
      "1.8809236288070679\n",
      "3.821436643600464\n",
      "4.070227146148682\n",
      "4.0608134269714355\n",
      "5.1780195236206055\n",
      "4.852879047393799\n",
      "5.455050468444824\n",
      "9.1979398727417\n",
      "7.730627059936523\n",
      "5.374883651733398\n",
      "4.667696952819824\n",
      "4.062681674957275\n",
      "4.430972099304199\n",
      "4.543846130371094\n",
      "4.772676944732666\n",
      "4.666430473327637\n",
      "5.39125394821167\n",
      "5.0661773681640625\n",
      "4.3363938331604\n",
      "4.503657341003418\n",
      "4.597201347351074\n",
      "4.1091461181640625\n",
      "3.8817734718322754\n",
      "3.720628499984741\n",
      "3.2624335289001465\n",
      "2.661238670349121\n",
      "2.8754453659057617\n",
      "4.6202497482299805\n",
      "4.398224830627441\n",
      "3.601149797439575\n",
      "3.0996599197387695\n",
      "3.476022481918335\n",
      "3.5771236419677734\n",
      "3.151602268218994\n",
      "torch.Size([2, 9741952])\n"
     ]
    }
   ],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:45:50.635595Z",
     "start_time": "2025-06-22T19:45:42.638119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "def smear(chunks, smear_width):\n",
    "    envelope = 0.5*(1-torch.cos(torch.linspace(0, 2*math.pi, 2*smear_width+1)))\n",
    "    #for i in range(smear_width+1, 2*smear_width+1):\n",
    "    #    envelope[i] = 0\n",
    "    print(envelope)\n",
    "    for i in range(len(chunks)-smear_width*2-1):\n",
    "        smear_sources = [\n",
    "            chunks[i+chunk_index] * envelope[chunk_index]\n",
    "            #(i+chunk_index, envelope[chunk_index])\n",
    "            for chunk_index in range(0, min(len(chunks), smear_width*2+1))\n",
    "        ]\n",
    "        #print(smear_sources)\n",
    "        #print(set([ss.shape for ss in smear_sources]))\n",
    "        #print(torch.sum(torch.stack(smear_sources), dim=0))\n",
    "        smeared_chunk = torch.sum(torch.stack(smear_sources), dim=0) / len(smear_sources)\n",
    "        #print(smeared_chunk.shape)\n",
    "        #break\n",
    "        yield smeared_chunk\n",
    "        \n",
    "def smear_2(original_order_chunks_no_window, sort_order, smear_width, spread=4, \n",
    "            smear_mode=Literal['in', 'in-out'],\n",
    "            dynamic_smear_width_embeds: tuple[torch.Tensor, list[int], list[int]]=None):\n",
    "    \n",
    "    def get_envelope(smear_width):\n",
    "        envelope = 0.5*(1-torch.cos(torch.linspace(0, 2*math.pi, 2*smear_width+1)))\n",
    "        if smear_mode == 'in':\n",
    "            for i in range(smear_width+1, 2*smear_width+1):\n",
    "                envelope[i] = 0\n",
    "        return envelope\n",
    "    envelope = get_envelope(smear_width)\n",
    "    print(envelope)\n",
    "    num_chunks = len(original_order_chunks_no_window)\n",
    "    smeared_chunks = [torch.zeros_like(original_order_chunks_no_window[0]) \n",
    "                     for _ in range(num_chunks)]\n",
    "    for position_idx in tqdm(range(num_chunks), total=num_chunks):\n",
    "        source_chunk_idx = sort_order[position_idx]\n",
    "        \n",
    "        if dynamic_smear_width_embeds is not None:\n",
    "            source_chunk_embed = all_features[source_chunk_idx]\n",
    "            logits = source_chunk_embed @ dynamic_smear_width_embeds[0].T\n",
    "            #print(logits)\n",
    "            #print(logits.softmax(dim=0))\n",
    "            logits_norm = logits / logits.sum()\n",
    "            smooth_dynamic_smear = True\n",
    "            if smooth_dynamic_smear:\n",
    "                smear_width = torch.sum(\n",
    "                    logits_norm \n",
    "                    * torch.tensor(dynamic_smear_width_embeds[1]).to(device)\n",
    "                ).item()\n",
    "                spread = torch.sum(\n",
    "                    logits_norm \n",
    "                    * torch.tensor(dynamic_smear_width_embeds[2]).to(device)\n",
    "                ).item()\n",
    "                print(smear_width, spread)\n",
    "                smear_width = max(round(smear_width), 1)\n",
    "                spread = max(round(spread), 1)\n",
    "            else:\n",
    "                smear_width = dynamic_smear_width_embeds[1][int(logits_norm.argmax().item())]\n",
    "                spread = dynamic_smear_width_embeds[2][int(logits_norm.argmax().item())]\n",
    "                print(smear_width, spread)\n",
    "            envelope = get_envelope(smear_width)\n",
    "        #volume_scaling = 1/envelope.sum()\n",
    "                    \n",
    "        for smear_slot in range(-smear_width, smear_width+1):\n",
    "            for spread_slot in range(-spread, spread+1):\n",
    "                smeared_chunks[\n",
    "                    wrap(position_idx+smear_slot+spread_slot, num_chunks)\n",
    "                ] += (\n",
    "                        original_order_chunks_no_window[\n",
    "                            wrap(source_chunk_idx+spread_slot, num_chunks)]\n",
    "                        * envelope[smear_slot+smear_width] \n",
    "                        * (1/((spread+1)*envelope.sum()))\n",
    "                )\n",
    "\n",
    "    for smeared_chunk in smeared_chunks:\n",
    "        yield smeared_chunk\n",
    "        \n",
    "    #for i \n",
    "spread = 4\n",
    "smear_width = 1\n",
    "smear_mode = 'in-out'\n",
    "\n",
    "dynamic_smear_width_defs = [('dreamy, mysterious, sparse', 6, 1), \n",
    "                            ('driving, rhythmic, instrumental, simple beat', 2, 2), \n",
    "                            ('intense, emotional, screaming, wailing', 1, 6)]\n",
    "print(tokenizer('stuff', padding=True, return_tensors='pt').input_ids)\n",
    "\n",
    "dynamic_smear_width_embeds = (\n",
    "    torch.concat([get_text_features(t) for t, _, _ in dynamic_smear_width_defs]),\n",
    "    [w for _, w, _ in dynamic_smear_width_defs],\n",
    "    [s for _, _, s in dynamic_smear_width_defs]\n",
    ")\n",
    "\n",
    "smeared_chunks = list(smear_2(stereo_chunks_no_window, sort_order=sort_order, smear_width=smear_width, spread=spread, smear_mode=smear_mode, \n",
    "                              dynamic_smear_width_embeds=dynamic_smear_width_embeds\n",
    "                              ))\n",
    "#print(Counter([len(c) for c in smeared_chunks]))\n",
    "smeared = torch.cat(smeared_chunks, dim=1)\n",
    "print(smeared.shape)\n",
    "torchaudio.save(filename + f'-sorted-norm-bpm{bpm}-cb{chunk_beats}-ww{window_width}-smeared-sm_{smear_mode}-sw{smear_width}-spread_actual{spread}-dyn3d.wav', smeared, sample_rate=sampling_rate)\n"
   ],
   "id": "c11ef4e4ff8baf4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0, 40110,     2]])\n",
      "tensor([0., 1., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d493c6e131d04302a61b1cab2dca4101"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4786715507507324 2.9209675788879395\n",
      "2.489936351776123 3.0018739700317383\n",
      "2.7422468662261963 3.017498254776001\n",
      "2.235888957977295 3.479130268096924\n",
      "2.5422704219818115 3.2330713272094727\n",
      "2.246544361114502 3.4490702152252197\n",
      "2.2521414756774902 3.1082358360290527\n",
      "2.3773345947265625 2.8961308002471924\n",
      "2.4339187145233154 2.384483814239502\n",
      "2.0919060707092285 2.802823781967163\n",
      "2.621413230895996 2.274388313293457\n",
      "3.0837583541870117 1.498881459236145\n",
      "2.3414859771728516 1.578080177307129\n",
      "2.952702522277832 2.400308132171631\n",
      "2.7558298110961914 2.420318365097046\n",
      "2.7713584899902344 2.5322206020355225\n",
      "3.122119903564453 1.9842698574066162\n",
      "2.856539726257324 2.3369927406311035\n",
      "3.017334222793579 2.272874355316162\n",
      "2.782302141189575 2.4345202445983887\n",
      "2.9405951499938965 2.2053489685058594\n",
      "2.8800487518310547 2.2697250843048096\n",
      "2.408787727355957 2.9241814613342285\n",
      "2.615767478942871 2.404205799102783\n",
      "2.7111291885375977 2.4358086585998535\n",
      "3.0090394020080566 2.190105438232422\n",
      "2.967474937438965 2.3274946212768555\n",
      "2.829333782196045 2.426645278930664\n",
      "2.92155385017395 2.4737329483032227\n",
      "2.802793502807617 2.6722192764282227\n",
      "2.7293944358825684 2.6669740676879883\n",
      "2.5917413234710693 2.5811336040496826\n",
      "2.703890323638916 2.4509711265563965\n",
      "2.7889537811279297 2.3622231483459473\n",
      "2.7836685180664062 2.478581428527832\n",
      "2.9381141662597656 2.3885879516601562\n",
      "3.1045846939086914 2.172290802001953\n",
      "3.1975364685058594 2.0309174060821533\n",
      "3.243088960647583 1.940995454788208\n",
      "3.0760903358459473 2.1957645416259766\n",
      "3.1345810890197754 1.9141932725906372\n",
      "3.0552804470062256 2.1016342639923096\n",
      "3.049651622772217 2.0642035007476807\n",
      "2.981389045715332 2.224501848220825\n",
      "3.2337570190429688 1.876854658126831\n",
      "3.1782846450805664 1.9268161058425903\n",
      "3.269298791885376 1.8665835857391357\n",
      "3.379678964614868 1.6294569969177246\n",
      "3.238405704498291 1.8123443126678467\n",
      "3.171661853790283 1.8190994262695312\n",
      "3.445310354232788 1.511628270149231\n",
      "3.2265706062316895 1.6895620822906494\n",
      "3.1840367317199707 1.7715961933135986\n",
      "3.6150264739990234 1.0345053672790527\n",
      "3.351579189300537 1.50869619846344\n",
      "4.289188861846924 -0.21328341960906982\n",
      "4.785360336303711 -1.2012221813201904\n",
      "4.979952812194824 -1.763719081878662\n",
      "3.7798633575439453 0.37067925930023193\n",
      "3.5402824878692627 0.4412893056869507\n",
      "4.212370872497559 0.18434643745422363\n",
      "4.556609153747559 -0.12481546401977539\n",
      "4.384625434875488 -0.8623507022857666\n",
      "3.219215154647827 1.0557459592819214\n",
      "3.621192216873169 0.9482121467590332\n",
      "3.6040115356445312 1.008592963218689\n",
      "3.512932777404785 1.301084280014038\n",
      "3.661411762237549 0.9348651170730591\n",
      "3.8995168209075928 0.19456946849822998\n",
      "3.894376754760742 -0.12996292114257812\n",
      "3.642216682434082 0.881937563419342\n",
      "3.7844886779785156 0.7343116402626038\n",
      "3.681173801422119 0.8584003448486328\n",
      "3.679701805114746 1.285908579826355\n",
      "3.3880763053894043 1.6587225198745728\n",
      "4.0498046875 0.014123678207397461\n",
      "3.915496826171875 -0.08100056648254395\n",
      "4.004810810089111 0.3316739797592163\n",
      "3.8851637840270996 0.15950191020965576\n",
      "4.725314617156982 -0.2134636640548706\n",
      "4.64943790435791 -0.16947245597839355\n",
      "5.180477142333984 -0.6540818214416504\n",
      "5.230287075042725 -0.5917562246322632\n",
      "4.247623443603516 0.860569179058075\n",
      "4.043935775756836 1.2123923301696777\n",
      "4.143317222595215 1.0014195442199707\n",
      "4.0611138343811035 1.1689858436584473\n",
      "3.919398069381714 1.2844321727752686\n",
      "4.031543731689453 1.0463588237762451\n",
      "3.8752317428588867 1.217984676361084\n",
      "4.5825605392456055 1.5049707889556885\n",
      "6.097554683685303 -0.5448281168937683\n",
      "6.787369728088379 -1.8272584676742554\n",
      "6.270851135253906 -1.513864278793335\n",
      "8.486010551452637 -2.630582332611084\n",
      "9.016170501708984 -2.814800262451172\n",
      "10.705892562866211 -4.530058860778809\n",
      "99.63001251220703 -102.05988311767578\n",
      "7.965425968170166 -2.291827917098999\n",
      "7.470884323120117 -2.187542676925659\n",
      "3.6440317630767822 2.0919103622436523\n",
      "4.130562782287598 0.4373875856399536\n",
      "3.714783191680908 1.2741698026657104\n",
      "3.545269012451172 1.3985066413879395\n",
      "3.8992836475372314 0.8229783773422241\n",
      "4.002254486083984 0.8760344982147217\n",
      "3.836298942565918 1.349333643913269\n",
      "4.291665077209473 0.8564295768737793\n",
      "3.6046247482299805 1.7309894561767578\n",
      "3.2879207134246826 2.2297961711883545\n",
      "3.2750983238220215 1.7550148963928223\n",
      "2.689488649368286 2.7112340927124023\n",
      "2.254798650741577 2.160080909729004\n",
      "2.188854455947876 2.77606201171875\n",
      "1.9336912631988525 3.736884593963623\n",
      "3.0107626914978027 2.65401554107666\n",
      "3.1147334575653076 2.5006446838378906\n",
      "3.116931438446045 2.509026050567627\n",
      "3.412065029144287 1.9209020137786865\n",
      "3.2349157333374023 2.06368350982666\n",
      "3.4158670902252197 1.8135221004486084\n",
      "3.9044313430786133 0.8893088698387146\n",
      "3.8408823013305664 1.122824788093567\n",
      "3.446951389312744 1.8392720222473145\n",
      "3.2554688453674316 2.156388282775879\n",
      "2.968637466430664 2.4401655197143555\n",
      "3.057131767272949 2.2474474906921387\n",
      "3.0001511573791504 2.1793437004089355\n",
      "2.8944735527038574 2.0733351707458496\n",
      "2.9720914363861084 2.121608257293701\n",
      "3.0504870414733887 1.8788037300109863\n",
      "3.082773208618164 1.9766303300857544\n",
      "2.961225986480713 2.273017168045044\n",
      "3.038300037384033 2.2058401107788086\n",
      "3.0776712894439697 2.16713547706604\n",
      "2.9569578170776367 2.4041965007781982\n",
      "2.902965545654297 2.536579132080078\n",
      "2.8284034729003906 2.6159589290618896\n",
      "2.634542942047119 2.873361587524414\n",
      "2.343324661254883 3.214318037033081\n",
      "2.4091267585754395 2.992879629135132\n",
      "2.873586416244507 2.12660813331604\n",
      "2.837913990020752 2.210254192352295\n",
      "2.7176055908203125 2.6269383430480957\n",
      "2.6016244888305664 3.0396769046783447\n",
      "2.6399388313293457 2.6607298851013184\n",
      "2.685547351837158 2.6184988021850586\n",
      "2.5189857482910156 2.8330068588256836\n",
      "torch.Size([2, 9741952])\n"
     ]
    }
   ],
   "execution_count": 214
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T19:40:23.414004Z",
     "start_time": "2025-06-22T19:40:23.301610Z"
    }
   },
   "cell_type": "code",
   "source": "torch.tensor([1, 2, 3]).argmax()",
   "id": "6463b343db5b4966",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 210
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import Literal\n",
    "import math\n",
    "\n",
    "def smear(chunks, smear_width):\n",
    "    envelope = 0.5*(1-torch.cos(torch.linspace(0, 2*math.pi, 2*smear_width+1)))\n",
    "    #for i in range(smear_width+1, 2*smear_width+1):\n",
    "    #    envelope[i] = 0\n",
    "    print(envelope)\n",
    "    for i in range(len(chunks)-smear_width*2-1):\n",
    "        smear_sources = [\n",
    "            chunks[i+chunk_index] * envelope[chunk_index]\n",
    "            #(i+chunk_index, envelope[chunk_index])\n",
    "            for chunk_index in range(0, min(len(chunks), smear_width*2+1))\n",
    "        ]\n",
    "        #print(smear_sources)\n",
    "        #print(set([ss.shape for ss in smear_sources]))\n",
    "        #print(torch.sum(torch.stack(smear_sources), dim=0))\n",
    "        smeared_chunk = torch.sum(torch.stack(smear_sources), dim=0) / len(smear_sources)\n",
    "        #print(smeared_chunk.shape)\n",
    "        #break\n",
    "        yield smeared_chunk\n",
    "        \n",
    "def smear_2(original_order_chunks_no_window, sort_order, smear_width, spread=4, \n",
    "            smear_mode=Literal['in', 'in-out'],\n",
    "            dynamic_smear_width_embeds: tuple[torch.Tensor, list[int], list[int]]=None):\n",
    "    \n",
    "    def get_envelope(smear_width):\n",
    "        envelope = 0.5*(1-torch.cos(torch.linspace(0, 2*math.pi, 2*smear_width+1)))\n",
    "        if smear_mode == 'in':\n",
    "            for i in range(smear_width+1, 2*smear_width+1):\n",
    "                envelope[i] = 0\n",
    "        return envelope\n",
    "    envelope = get_envelope(smear_width)\n",
    "    print(envelope)\n",
    "    num_chunks = len(original_order_chunks_no_window)\n",
    "    smeared_chunks = [torch.zeros_like(original_order_chunks_no_window[0]) \n",
    "                     for _ in range(num_chunks)]\n",
    "    for position_idx in tqdm(range(num_chunks), total=num_chunks):\n",
    "        source_chunk_idx = sort_order[position_idx]\n",
    "        \n",
    "        if dynamic_smear_width_embeds is not None:\n",
    "            source_chunk_embed = all_features[source_chunk_idx]\n",
    "            logits = source_chunk_embed @ dynamic_smear_width_embeds[0].T\n",
    "            #print(logits)\n",
    "            #print(logits.softmax(dim=0))\n",
    "            logits_norm = logits / logits.sum()\n",
    "            smear_width = torch.sum(\n",
    "                logits_norm \n",
    "                * torch.tensor(dynamic_smear_width_embeds[1]).to(device)\n",
    "            ).item()\n",
    "            spread = torch.sum(\n",
    "                logits_norm \n",
    "                * torch.tensor(dynamic_smear_width_embeds[2]).to(device)\n",
    "            ).item()\n",
    "            print(smear_width, spread)\n",
    "            smear_width = max(round(smear_width), 1)\n",
    "            spread = max(round(spread), 1)\n",
    "            envelope = get_envelope(smear_width)\n",
    "                    \n",
    "        for smear_slot in range(-smear_width, smear_width+1):\n",
    "            for spread_slot in range(-spread, spread+1):\n",
    "                smeared_chunks[\n",
    "                    wrap(position_idx+smear_slot+spread_slot, num_chunks)\n",
    "                ] += (\n",
    "                        original_order_chunks_no_window[\n",
    "                            wrap(source_chunk_idx+spread_slot, num_chunks)]\n",
    "                        * envelope[smear_slot+smear_width] \n",
    "                        * (1/((spread+1)*smear_width))\n",
    "                )\n",
    "\n",
    "    for smeared_chunk in smeared_chunks:\n",
    "        yield smeared_chunk\n",
    "        \n",
    "    #for i \n",
    "smear_width = 1\n",
    "spread = 4\n",
    "smear_mode = 'in-out'\n",
    "\n",
    "dynamic_smear_width_defs = [('dreamy, mysterious, sparse', 6, 4), \n",
    "                            ('driving, rhythmic, instrumental, simple beat', 2, 2), \n",
    "                            ('intense, emotional, screaming, wailing', 1, 6)]\n",
    "print(tokenizer('stuff', padding=True, return_tensors='pt').input_ids)\n",
    "\n",
    "dynamic_smear_width_embeds = (\n",
    "    torch.concat([get_text_features(t) for t, _, _ in dynamic_smear_width_defs]),\n",
    "    [w for _, w, _ in dynamic_smear_width_defs],\n",
    "    [s for _, _, s in dynamic_smear_width_defs]\n",
    ")\n",
    "\n",
    "smeared_chunks = list(smear_2(stereo_chunks_no_window, sort_order=sort_order, smear_width=smear_width, spread=spread, smear_mode=smear_mode, \n",
    "                              dynamic_smear_width_embeds=dynamic_smear_width_embeds\n",
    "                              ))\n",
    "#print(Counter([len(c) for c in smeared_chunks]))\n",
    "smeared = torch.cat(smeared_chunks, dim=1)\n",
    "print(smeared.shape)\n",
    "torchaudio.save(filename + f'-sorted-norm-bpm{bpm}-cb{chunk_beats}-ww{window_width}-smeared-sm_{smear_mode}-sw{smear_width}-spread_actual{spread}-dyn3b.wav', smeared, sample_rate=sampling_rate)\n"
   ],
   "id": "9dba53f8186bff29"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
