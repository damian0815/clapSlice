{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T12:01:00.350842Z",
     "start_time": "2025-06-22T12:00:54.864896Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install datasets transformers librosa soundfile numpy\"<\"2 torch torchaudio fast-tsp kmedoids\n",
   "id": "b7880da606420f96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./venv/lib/python3.12/site-packages (3.6.0)\r\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.12/site-packages (4.52.4)\r\n",
      "Requirement already satisfied: librosa in ./venv/lib/python3.12/site-packages (0.11.0)\r\n",
      "Requirement already satisfied: soundfile in ./venv/lib/python3.12/site-packages (0.13.1)\r\n",
      "Requirement already satisfied: numpy<2 in ./venv/lib/python3.12/site-packages (1.26.4)\r\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.12/site-packages (2.2.1)\r\n",
      "Requirement already satisfied: torchaudio in ./venv/lib/python3.12/site-packages (2.2.1)\r\n",
      "Requirement already satisfied: fast-tsp in ./venv/lib/python3.12/site-packages (0.1.4)\r\n",
      "Collecting kmedoids\r\n",
      "  Obtaining dependency information for kmedoids from https://files.pythonhosted.org/packages/6e/b4/457e552aa362cc746fbf0c461ab1a9bd7794db3321f82586601769f27112/kmedoids-0.5.3.1-cp312-cp312-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata\r\n",
      "  Downloading kmedoids-0.5.3.1-cp312-cp312-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (9.6 kB)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from datasets) (3.18.0)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./venv/lib/python3.12/site-packages (from datasets) (20.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./venv/lib/python3.12/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (from datasets) (2.3.0)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in ./venv/lib/python3.12/site-packages (from datasets) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./venv/lib/python3.12/site-packages (from datasets) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in ./venv/lib/python3.12/site-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./venv/lib/python3.12/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in ./venv/lib/python3.12/site-packages (from datasets) (2025.3.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./venv/lib/python3.12/site-packages (from datasets) (0.33.0)\r\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from datasets) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from datasets) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./venv/lib/python3.12/site-packages (from transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.12/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./venv/lib/python3.12/site-packages (from librosa) (3.0.1)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in ./venv/lib/python3.12/site-packages (from librosa) (0.61.2)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.15.3)\r\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.7.0)\r\n",
      "Requirement already satisfied: joblib>=1.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.5.1)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./venv/lib/python3.12/site-packages (from librosa) (5.2.1)\r\n",
      "Requirement already satisfied: pooch>=1.1 in ./venv/lib/python3.12/site-packages (from librosa) (1.8.2)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./venv/lib/python3.12/site-packages (from librosa) (0.5.0.post1)\r\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in ./venv/lib/python3.12/site-packages (from librosa) (4.14.0)\r\n",
      "Requirement already satisfied: lazy_loader>=0.1 in ./venv/lib/python3.12/site-packages (from librosa) (0.4)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in ./venv/lib/python3.12/site-packages (from librosa) (1.1.1)\r\n",
      "Requirement already satisfied: cffi>=1.0 in ./venv/lib/python3.12/site-packages (from soundfile) (1.17.1)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.12/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.12/site-packages (from cffi>=1.0->soundfile) (2.22)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./venv/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\r\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./venv/lib/python3.12/site-packages (from numba>=0.51.0->librosa) (0.44.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./venv/lib/python3.12/site-packages (from pooch>=1.1->librosa) (4.3.8)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
      "Downloading kmedoids-0.5.3.1-cp312-cp312-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (915 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m915.7/915.7 kB\u001B[0m \u001B[31m9.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hInstalling collected packages: kmedoids\r\n",
      "Successfully installed kmedoids-0.5.3.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "3cb23ac2-7d44-42dc-8acf-0df92184c026",
   "metadata": {},
   "source": "# Setup"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T13:51:39.837622Z",
     "start_time": "2025-06-22T13:51:30.152196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device='mps'\n",
    "from transformers import ClapModel, ClapFeatureExtractor\n",
    "model = ClapModel.from_pretrained(\"laion/clap-htsat-unfused\", use_safetensors=True).to(device)\n",
    "feature_extractor: ClapFeatureExtractor = ClapFeatureExtractor.from_pretrained(\"laion/clap-htsat-unfused\")\n"
   ],
   "id": "5a78d7169b407d7d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run",
   "id": "6d42f4e095b6da6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T13:51:40.882429Z",
     "start_time": "2025-06-22T13:51:39.839534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "filename = '/Users/damian/Downloads/Dua Lipa - Be The One (Official Music Video).mp3'\n",
    "waveform, sampling_rate = torchaudio.load(filename)\n",
    "\n",
    "if sampling_rate != feature_extractor.sampling_rate:\n",
    "    resampler = T.Resample(sampling_rate,  feature_extractor.sampling_rate, dtype=waveform.dtype)\n",
    "    waveform, sampling_rate = resampler(waveform), feature_extractor.sampling_rate\n",
    "\n",
    "print(sampling_rate, waveform.shape)\n",
    "#inputs = feature_extractor(waveform, sampling_rate=sample_rate, return_tensors=\"pt\")\n",
    "#audio_features = model.get_audio_features(**inputs)"
   ],
   "id": "d5d30b5e7ea5cb98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 torch.Size([2, 9805880])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T13:59:28.768373Z",
     "start_time": "2025-06-22T13:59:28.728806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Generator\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def get_audio_chunks(waveform, chunk_size_seconds: float=0.25) -> Generator[torch.Tensor, None, None]:\n",
    "    if len(waveform.shape) != 1:\n",
    "        raise ValueError(\"waveform should have shape [num_samples]\")\n",
    "    chunk_size = int(8 * ((sampling_rate * chunk_size_seconds) // 8))\n",
    "    for offset in range(0, waveform.shape[0], chunk_size):\n",
    "        yield waveform[offset:offset+chunk_size]\n",
    "    \n",
    "\n",
    "def get_features_chunked(waveform: torch.Tensor, sampling_rate: int, chunk_size_seconds: float=0.25) -> torch.Tensor:\n",
    "    all_features = []\n",
    "    for chunk in get_audio_chunks(waveform, chunk_size_seconds=chunk_size_seconds):\n",
    "        inputs = feature_extractor(chunk, sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "        #print(inputs.keys())\n",
    "        audio_features = model.get_audio_features(input_features=inputs.input_features.to(device))\n",
    "        all_features.append(audio_features)\n",
    "        \n",
    "    return torch.concat(all_features)\n",
    "\n",
    "def get_features(waveform: torch.Tensor, sampling_rate):\n",
    "    inputs = feature_extractor(waveform, sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "    #print(inputs.keys())\n",
    "    audio_features = model.get_audio_features(input_features=inputs.input_features.to(device))\n",
    "    return audio_features\n",
    "\n"
   ],
   "id": "5b4b82f01c2ca14b",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:35:29.684008Z",
     "start_time": "2025-06-22T14:35:23.856307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bpm = 87.5/4\n",
    "chunk_size_seconds = 60/bpm\n",
    "left_chunks = list(get_audio_chunks(waveform[0], chunk_size_seconds=chunk_size_seconds))[:-1]\n",
    "right_chunks = list(get_audio_chunks(waveform[1], chunk_size_seconds=chunk_size_seconds))[:-1]\n",
    "mono_chunks = [(left_chunks[i] + right_chunks[i]) / 2 for i in range(len(left_chunks))]\n",
    "all_features = torch.concat([get_features(chunk, sampling_rate=sampling_rate) \n",
    "                             for chunk in tqdm(mono_chunks)])\n",
    "\n"
   ],
   "id": "c691f5b529b7e6c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1c3cd5a19624e939537ccaa659e4cc0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "700e4a18fc794f0191807d50330bb3b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "392fc7ff074f43e2a6195fe0c3473cc5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:35:30.490671Z",
     "start_time": "2025-06-22T14:35:30.446431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import pickle\n",
    "with open(filename + f'.clap-cs{chunk_size_seconds}.pkl', 'wb') as f:\n",
    "    pickle.dump(all_features, f)\n"
   ],
   "id": "33ba485e1b6afcc4",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:35:32.203628Z",
     "start_time": "2025-06-22T14:35:31.245415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.clap_slice.medoids_tsp import sort_tsp\n",
    "order = sort_tsp(all_features)"
   ],
   "id": "b6a9e3a09263202d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing distance matrix\n",
      "computing route\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:35:33.048716Z",
     "start_time": "2025-06-22T14:35:32.960551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chunks_sorted = [torch.stack([left_chunks[index], right_chunks[index]])\n",
    "    for index in order]\n",
    "print(chunks_sorted[0].shape)\n",
    "sorted_audio = torch.cat(chunks_sorted, dim=1)\n",
    "print(sorted_audio.shape)"
   ],
   "id": "87f9d40beaf70379",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 131656])\n",
      "torch.Size([2, 9742544])\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:35:35.695595Z",
     "start_time": "2025-06-22T14:35:35.372754Z"
    }
   },
   "cell_type": "code",
   "source": "torchaudio.save(filename + f'-sorted-cs{chunk_size_seconds}.wav', sorted_audio, sample_rate=sampling_rate)",
   "id": "7350c7926c1c6c7b",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:47:38.332582Z",
     "start_time": "2025-06-22T14:47:36.973123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "def smear(chunks, smear_width):\n",
    "    envelope = 0.5*(1-torch.cos(torch.linspace(0, 2*math.pi, 2*smear_width+1)))\n",
    "    print(envelope)\n",
    "    for i in range(len(chunks)-smear_width*2-1):\n",
    "        smear_sources = [\n",
    "            chunks[i+chunk_index] * envelope[chunk_index]\n",
    "            #(i+chunk_index, envelope[chunk_index])\n",
    "            for chunk_index in range(0, min(len(chunks), smear_width*2+1))\n",
    "        ]\n",
    "        #print(smear_sources)\n",
    "        #print(set([ss.shape for ss in smear_sources]))\n",
    "        #print(torch.sum(torch.stack(smear_sources), dim=0))\n",
    "        smeared_chunk = torch.sum(torch.stack(smear_sources), dim=0) / len(smear_sources)\n",
    "        #print(smeared_chunk.shape)\n",
    "        #break\n",
    "        yield smeared_chunk\n",
    "        \n",
    "def smear_2(chunks, smear_width):\n",
    "    envelope = 0.5*(1-torch.cos(torch.linspace(0, 2*math.pi, 2*smear_width+1)))\n",
    "    print(envelope)\n",
    "    def wrap(idx):\n",
    "        if idx < 0:\n",
    "            return len(chunks) + idx\n",
    "        elif idx >= len(chunks):\n",
    "            return idx - len(chunks)\n",
    "        else:\n",
    "            return idx\n",
    "    smeared_chunks = [torch.zeros_like(chunks[0]) \n",
    "                     for _ in range(len(chunks))]\n",
    "    for source_chunk_idx, chunk in enumerate(chunks):\n",
    "        for smear_slot in range(-smear_width, smear_width+1):\n",
    "            smeared_chunks[wrap(source_chunk_idx+smear_slot)] += chunk * envelope[smear_slot+smear_width] * (1/smear_width)\n",
    "\n",
    "    for smeared_chunk in smeared_chunks:\n",
    "        yield smeared_chunk\n",
    "        \n",
    "    #for i \n",
    "smeared_chunks = list(smear_2(chunks_sorted, 4))\n",
    "#print(Counter([len(c) for c in smeared_chunks]))\n",
    "smeared = torch.cat(smeared_chunks, dim=1)\n",
    "print(smeared.shape)\n",
    "torchaudio.save(filename + f'-sorted-cs{chunk_size_seconds}-smeared.wav', smeared, sample_rate=sampling_rate)\n"
   ],
   "id": "2e343d37b2782fd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.1464, 0.5000, 0.8536, 1.0000, 0.8536, 0.5000, 0.1464, 0.0000])\n",
      "torch.Size([2, 9742544])\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9dba53f8186bff29"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
